{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWmYuIqwXky9"
   },
   "source": [
    "# 作業 : 自行調整完整版 Bert 預訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjR0X3RKXkzH"
   },
   "source": [
    "# [作業目標]\n",
    "- 觀察並了解調整 Step4.3 類神經網路結構對結果帶來的影響\n",
    "- 觀察並了解調整 Step4.2 Batch Size 以及 Step4.4 的Optimizer & Learning Rate 對結果帶來的影響"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9OcW6i0XkzI"
   },
   "source": [
    "# [作業重點]\n",
    "- 程式最後會輸出 Kaggle 練習題的提交檔, 同學可以藉由提交分數驗證結果\n",
    "- 請同學在修改時, 記得以檔名或其他形式保留調整的紀錄, 以免忘記最佳輸出的調整方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HiLyC9ZXkzJ"
   },
   "source": [
    "# 載入資料與套件, 進行切割與預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eVDiQwbCXkzJ"
   },
   "outputs": [],
   "source": [
    "# 載入相關套件\n",
    "import os\n",
    "import re, warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UngfxH5AXkzK"
   },
   "outputs": [],
   "source": [
    "# 將訓練資料切割成 訓練集 / 驗證集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df =  pd.read_csv('data/nlp-getting-started/train.csv')\n",
    "X = df.text.values\n",
    "y = df.target.values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v6PqS3WeXkzK",
    "outputId": "90eef939-d7c3-4160-8948-33839e178970"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>7732</td>\n",
       "      <td>My day isn't going the way I planned so I'm lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>1843</td>\n",
       "      <td>@Kyra_Elizabethh my back break light is burned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>7308</td>\n",
       "      <td>@MaximEristavi Meanwhile in Finland: Nuclear p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>3600</td>\n",
       "      <td>desolation #bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>5402</td>\n",
       "      <td>Truck driver died in Turnpike fire most lanes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "2314  7732  My day isn't going the way I planned so I'm lo...\n",
       "563   1843  @Kyra_Elizabethh my back break light is burned...\n",
       "2184  7308  @MaximEristavi Meanwhile in Finland: Nuclear p...\n",
       "1092  3600                                  desolation #bored\n",
       "1600  5402  Truck driver died in Turnpike fire most lanes ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入測試資料\n",
    "test_df = pd.read_csv('data/nlp-getting-started/test.csv')\n",
    "test_df = test_df[['id', 'text']]\n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e_wESyxZXkzM",
    "outputId": "3631d01d-fedf-43fb-b621-54cf12e0ad06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# 載入 pytorch 套件, 依照現有環境判定是否使用 GPU 計算\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4P4Azey2XkzN"
   },
   "outputs": [],
   "source": [
    "# 簡化版前處理\n",
    "def text_preprocessing(text):\n",
    "    # 移除推特的姓名標籤 ('@name')\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    # 將 '&amp;' 替換成 '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "    # 移除文末的空白字元\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RdhdTZhXXkzN",
    "outputId": "ff15215a-c612-4312-b456-665794f8782c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "Processed:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n"
     ]
    }
   ],
   "source": [
    "# 印出第一組推文在前處理之前與之後的改變\n",
    "print('Original: ', X[0])\n",
    "print('Processed: ', text_preprocessing(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZYjqFAZXkzN"
   },
   "source": [
    "# Step 4.1 : 載入 Bert 套件與 tokenizer, 將本文編碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dnA2rPKYXkzO"
   },
   "outputs": [],
   "source": [
    "# 載入 Bert 套件與 tokenizer\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# 設定 Bert 的前處理函數\n",
    "def preprocessing_for_bert(data):\n",
    "    # 初始化要傳回的資料\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    # 把所有文句用 tokenizer 編碼\n",
    "    for sent in data:\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # 套用簡化版前處理函數\n",
    "            add_special_tokens=True,        # 加上 `[CLS]` 與 `[SEP]`\n",
    "            max_length=MAX_LEN,             # 需要填充的最大長度\n",
    "            pad_to_max_length=True,         # 是否要填充到最大長度\n",
    "            return_attention_mask=True      # 是否傳回 attention mask\n",
    "            )        \n",
    "        # 更新要傳回的資料\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "    # 將傳回資料轉為 tensor\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D9ezEZMyXkzO",
    "outputId": "3b5100be-1747-4ea5-acf2-43b58b21d161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  84\n"
     ]
    }
   ],
   "source": [
    "# 將訓練資料與測試資料的\"推文\"合併\n",
    "all_tweets = np.concatenate([df.text.values, test_df.text.values])\n",
    "\n",
    "# 將推文使用 tokenizer 加以編碼\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
    "\n",
    "# 找出最大的推文長度 (訓練資料 + 預測目標資料)\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ov-IWDOKXkzP",
    "outputId": "3a54abe2-5cd5-4061-ab2e-5ce65dc4a451"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "Token IDs:  [101, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# 將上一格的 Max length 數值填入\n",
    "MAX_LEN = 84\n",
    "\n",
    "# 顯示第一筆資料的推文與期經過 Bert 的前處理函數 (preprocessing_for_bert) 的編碼結果 (確認函數正確)\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "# 使用 preprocessing_for_bert 將訓練 / 驗證集的推文進行編碼\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY6IgL0KXkzP"
   },
   "source": [
    "# Step 4.2 : Fine Tune 前的準備 - 設定 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2iDpz5UUXkzQ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# 將訓練與驗證目標值轉為 torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# 要微調 (fine-tuning) BERT 時, 原作者建議的 batch size 為 16 或 32\n",
    "batch_size = 32\n",
    "\n",
    "# 設定訓練與驗證集的 DataLoader\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFNtfKhaXkzQ"
   },
   "source": [
    "# Step 4.3 : 設定 Bert 連接目標值的 Layer 結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gyE5aOSjXkzR",
    "outputId": "482ec518-9650-414e-9ca4-bee0cb27cdac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 278 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 載入 pytorch 與 Bert 相關套件\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# 自定義 Bert 分類器函數\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # 指定 BERT 輸入長度大小(D_in), 分類器的隱藏層大小(H), 以及分類目標值的種類數量(D_out)\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "        # 載入 Bert 預訓練權重作為初始值\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # 初始化自定義分類器的類神經網路\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "        # 凍結 Bert 部分的權重\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 將資料輸入 BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)        \n",
    "        # 將輸出結果存在 last_hidden_state_cls 中\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "        # 將輸出結果輸入自定義分類器\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOxS-dcOXkzS"
   },
   "source": [
    "# Step 4.4 : Optimizer & Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "g6ihaa8zXkzS"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    # 初始化 Bert 分類器\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "    # 告訴 PyTorch 模型需要在 GPU 上執行\n",
    "    bert_classifier.to(device)\n",
    "    # 設定 optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # 預設的學習速率\n",
    "                      eps=1e-8    # 預設的 epsilon 值\n",
    "                      )\n",
    "    # 計算總共的訓練步數\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    # 設定學習率排程\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # 預設值\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5YvwYTdLXkzT"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# 設定損失函數\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    # 開始訓練迴圈\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # 印出變數表格標題\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "        # 測量每個 epoch 的執行時間\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "        # 每個 epoch 開始時重置追蹤的變數\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "        # 將模型切換到訓練模式\n",
    "        model.train()\n",
    "        # 訓練資料的每個 batch \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # 將所有 batch 資料載入 GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "            # 將模型中之前計算的梯度歸零\n",
    "            model.zero_grad()\n",
    "            # 執行一個向前傳遞. 這會傳回一個 logit 值\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "            # 計算並累加損失值\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            # 執行一個向後傳遞以計算梯度\n",
    "            loss.backward()\n",
    "            # 將梯度侷限在正負 1 範圍內, 防止梯度爆炸\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            # 更新參數與學習率\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            # 每 20 個 batches 印出損失值與執行時間一次\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # 計算 20 batches 的執行時間\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "                # 印出訓練結果\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "                # 重置 batch 追蹤變數\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "        # 計算全部訓練資料的平均損失值\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        if evaluation == True:\n",
    "            # 每個 epoch 訓練完畢後, 在驗證集上檢驗模型的表現\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "            time_elapsed = time.time() - t0_epoch            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    # 將模型切換到評量模式 : 此模式下暫停使用 dropout 層\n",
    "    model.eval()\n",
    "    # 紀錄評量函數\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    # 驗證資料的每個 batch \n",
    "    for batch in val_dataloader:\n",
    "        # 將所有 batch 資料載入 GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "        # 計算 logit 值\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        # 計算損失值\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "        # 取得預測值\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        # 計算 accuracy 數值\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "    # 計算全部驗證資料的平均損失值與平均 accuracy\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkh_UvM2XkzU"
   },
   "source": [
    "# 執行跑參 : 依機器的計算能力調整 epoch 大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "F2pkguY7XkzU",
    "outputId": "e1fc96d0-dda8-494e-8038-f3e88b54a25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.559136   |     -      |     -     |  203.03  \n",
      "   1    |   40    |   0.470453   |     -      |     -     |  189.32  \n",
      "   1    |   60    |   0.469276   |     -      |     -     |  190.11  \n",
      "   1    |   80    |   0.434589   |     -      |     -     |  191.27  \n",
      "   1    |   100   |   0.431764   |     -      |     -     |  196.15  \n",
      "   1    |   120   |   0.469567   |     -      |     -     |  197.41  \n",
      "   1    |   140   |   0.410726   |     -      |     -     |  266.30  \n",
      "   1    |   160   |   0.355852   |     -      |     -     |  464.64  \n",
      "   1    |   180   |   0.418378   |     -      |     -     |  408.68  \n",
      "   1    |   200   |   0.437822   |     -      |     -     |  440.88  \n",
      "   1    |   214   |   0.373442   |     -      |     -     |  280.65  \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.441575   |  0.413500  |   82.82   |  3163.65 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.306428   |     -      |     -     |  489.08  \n",
      "   2    |   40    |   0.282132   |     -      |     -     |  423.67  \n",
      "   2    |   60    |   0.319586   |     -      |     -     |  379.46  \n",
      "   2    |   80    |   0.264136   |     -      |     -     |  415.43  \n",
      "   2    |   100   |   0.335301   |     -      |     -     |  479.87  \n",
      "   2    |   120   |   0.308620   |     -      |     -     |  480.88  \n",
      "   2    |   140   |   0.274830   |     -      |     -     |  481.18  \n",
      "   2    |   160   |   0.277476   |     -      |     -     |  495.41  \n",
      "   2    |   180   |   0.244560   |     -      |     -     |  486.09  \n",
      "   2    |   200   |   0.267741   |     -      |     -     |  447.68  \n",
      "   2    |   214   |   0.329811   |     -      |     -     |  315.62  \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.290884   |  0.456118  |   82.59   |  5036.75 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42) # 設定隨機種子\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaxNnaM4XkzU"
   },
   "source": [
    "# 繪製 ROC_AUC 圖形 : 藉此觀察預測效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "phdGa5X5XkzU"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    # 將模型切換到評量模式 : 此模式下暫停使用 dropout 層\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "\n",
    "    # 測試資料的每個 batch \n",
    "    for batch in test_dataloader:\n",
    "        # 將所有 batch 資料載入 GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "        # 計算機率\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)    \n",
    "    # 將每個 batch 的 logit 值連結起來\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    # 使用 softmax 計算機率\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2nK6w-NyXkzV"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')       \n",
    "    # 取得測試集的 accuracy 值\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')    \n",
    "    # 繪製 ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r5Rx4KwpXkzV",
    "outputId": "1ce346fb-73ac-45f7-ddfe-1608d472f11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8858\n",
      "Accuracy: 82.55%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 在測試集上計算預測機率\n",
    "probs = bert_predict(bert_classifier, val_dataloader)\n",
    "# 評價 Bert 分類器\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3FtqgxMXkzW"
   },
   "source": [
    "# 重新以完整資料訓練模型, 並對要預測的資料進行輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "B0KT0n72XkzW",
    "outputId": "0690e62d-8e90-4929-d9eb-416218c67836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.562820   |     -      |     -     |  399.81  \n",
      "   1    |   40    |   0.495038   |     -      |     -     |  419.10  \n",
      "   1    |   60    |   0.423127   |     -      |     -     |  491.49  \n",
      "   1    |   80    |   0.444045   |     -      |     -     |  494.05  \n",
      "   1    |   100   |   0.443163   |     -      |     -     |  460.94  \n",
      "   1    |   120   |   0.449477   |     -      |     -     |  493.33  \n",
      "   1    |   140   |   0.373378   |     -      |     -     |  415.02  \n",
      "   1    |   160   |   0.380570   |     -      |     -     |  486.43  \n",
      "   1    |   180   |   0.399936   |     -      |     -     |  438.70  \n",
      "   1    |   200   |   0.426055   |     -      |     -     |  472.71  \n",
      "   1    |   220   |   0.416090   |     -      |     -     |  400.79  \n",
      "   1    |   237   |   0.402876   |     -      |     -     |  325.99  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.322805   |     -      |     -     |  453.10  \n",
      "   2    |   40    |   0.269458   |     -      |     -     |  383.08  \n",
      "   2    |   60    |   0.350561   |     -      |     -     |  425.51  \n",
      "   2    |   80    |   0.327068   |     -      |     -     |  406.01  \n",
      "   2    |   100   |   0.332393   |     -      |     -     |  406.33  \n",
      "   2    |   120   |   0.266513   |     -      |     -     |  431.26  \n",
      "   2    |   140   |   0.276023   |     -      |     -     |  415.76  \n",
      "   2    |   160   |   0.255046   |     -      |     -     |  404.62  \n",
      "   2    |   180   |   0.250842   |     -      |     -     |  418.18  \n",
      "   2    |   200   |   0.284841   |     -      |     -     |  432.31  \n",
      "   2    |   220   |   0.255757   |     -      |     -     |  422.90  \n",
      "   2    |   237   |   0.313168   |     -      |     -     |  349.72  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 連結訓練集與驗證集\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
    "\n",
    "# 在完整的訓練資料上重新訓練 Bert 分類器\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, full_train_dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "42F9JoIzXkzX",
    "outputId": "a8eadd83-1c74-4a55-860f-b85303299d1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>8051</td>\n",
       "      <td>Refugees as citizens - The Hindu http://t.co/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>425</td>\n",
       "      <td>@5SOStag honestly he could say an apocalypse i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1330</td>\n",
       "      <td>If you bored as shit don't nobody fuck wit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>663</td>\n",
       "      <td>@RealTwanBrown Yesterday I Had A Heat Attack ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>2930</td>\n",
       "      <td>The Devil Wears Prada is still one of my favou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "2406  8051  Refugees as citizens - The Hindu http://t.co/G...\n",
       "134    425  @5SOStag honestly he could say an apocalypse i...\n",
       "411   1330  If you bored as shit don't nobody fuck wit you...\n",
       "203    663  @RealTwanBrown Yesterday I Had A Heat Attack ?...\n",
       "889   2930  The Devil Wears Prada is still one of my favou..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8imzaomzXkzY",
    "outputId": "9697ebf1-e213-4ebc-b646-ba3b1fbc6a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# 在測試集推文上執行 `preprocessing_for_bert` 函數\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(test_df['text'])\n",
    "# 宣告測試集的 DataLoader\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AM4o-sxDXkzZ",
    "outputId": "597f6499-e02a-4c4b-c729-d53068768755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets predicted non-negative:  964\n"
     ]
    }
   ],
   "source": [
    "# 在測試資料上計算最終預測機率\n",
    "probs = bert_predict(bert_classifier, test_dataloader)\n",
    "# 將機率值轉為預測(超過門檻的預測為 1, 否則為 0)\n",
    "threshold = 0.9\n",
    "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
    "# 顯示被判定為\n",
    "print(\"Number of tweets predicted non-negative: \", preds.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mtjcf_WwXkza"
   },
   "outputs": [],
   "source": [
    "# 生成提交擋\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_df['id']\n",
    "submission['target'] = preds\n",
    "submission.to_csv('submission_FineTuneBert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_a_1BDeXkza"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CH39_作業.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
