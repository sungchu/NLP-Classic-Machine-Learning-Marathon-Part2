{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5Pf_RxOIAYv"
   },
   "source": [
    "### 作業目的: 透過實作加速版word2vec Skip-gram模型來更加了解高速版的word2vec\n",
    "\n",
    "本次作業會採用Penn Tree Bank資料及，學員可以在ptb.train.txt中取得訓練文本資料。這次作業可以讓學員練習到以pytorch搭建模型與進行文本資料的前處理\n",
    "\n",
    "PS: 建議學員使用Colab (或可以使用GPU加速的機器)來進行作業，不然訓練會訓練到天荒地老....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO-a6e2OI5zg"
   },
   "source": [
    "### Connect to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 14937,
     "status": "ok",
     "timestamp": 1606320756664,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "LXPU7BI3HNJ6"
   },
   "outputs": [],
   "source": [
    "# # Import libraries for importing files from Google drive to Colab\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# # Authorize Google SDK to access Google Drive from Colab\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 17072,
     "status": "ok",
     "timestamp": 1606320758810,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "D2E7yb-qI9Uv"
   },
   "outputs": [],
   "source": [
    "# download = drive.CreateFile({'id': '請自行輸入自己上傳google drive檔案的連結id'})\n",
    "# download.GetContentFile('ptb.train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKKpFV6GJwhs"
   },
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4149,
     "status": "ok",
     "timestamp": 1606320764926,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "Yjz-fWmbJRPB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import urllib.request\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3426,
     "status": "ok",
     "timestamp": 1606320764930,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "i9xrgPu3KBgJ",
    "outputId": "341dcbac-256c-45ee-ed8d-3ee0c1fb03b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 42068 lines\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料\n",
    "\n",
    "# Penn Tree Back dataset\n",
    "with open(\"./ptb.train.txt\", encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"Total {len(lines)} lines\")\n",
    "raw_dataset = [line.split() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2988,
     "status": "ok",
     "timestamp": 1606320764931,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "oAcF_5CQKH_J",
    "outputId": "b42ef993-9894-4061-f8df-3f929fe17114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aer',\n",
       "  'banknote',\n",
       "  'berlitz',\n",
       "  'calloway',\n",
       "  'centrust',\n",
       "  'cluett',\n",
       "  'fromstein',\n",
       "  'gitano',\n",
       "  'guterman',\n",
       "  'hydro-quebec',\n",
       "  'ipo',\n",
       "  'kia',\n",
       "  'memotec',\n",
       "  'mlx',\n",
       "  'nahb',\n",
       "  'punts',\n",
       "  'rake',\n",
       "  'regatta',\n",
       "  'rubens',\n",
       "  'sim',\n",
       "  'snack-food',\n",
       "  'ssangyong',\n",
       "  'swapo',\n",
       "  'wachter'],\n",
       " ['pierre',\n",
       "  '<unk>',\n",
       "  'N',\n",
       "  'years',\n",
       "  'old',\n",
       "  'will',\n",
       "  'join',\n",
       "  'the',\n",
       "  'board',\n",
       "  'as',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'nov.',\n",
       "  'N'],\n",
       " ['mr.',\n",
       "  '<unk>',\n",
       "  'is',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  '<unk>',\n",
       "  'n.v.',\n",
       "  'the',\n",
       "  'dutch',\n",
       "  'publishing',\n",
       "  'group'],\n",
       " ['rudolph',\n",
       "  '<unk>',\n",
       "  'N',\n",
       "  'years',\n",
       "  'old',\n",
       "  'and',\n",
       "  'former',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  'consolidated',\n",
       "  'gold',\n",
       "  'fields',\n",
       "  'plc',\n",
       "  'was',\n",
       "  'named',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'of',\n",
       "  'this',\n",
       "  'british',\n",
       "  'industrial',\n",
       "  'conglomerate'],\n",
       " ['a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'asbestos',\n",
       "  'once',\n",
       "  'used',\n",
       "  'to',\n",
       "  'make',\n",
       "  'kent',\n",
       "  'cigarette',\n",
       "  'filters',\n",
       "  'has',\n",
       "  'caused',\n",
       "  'a',\n",
       "  'high',\n",
       "  'percentage',\n",
       "  'of',\n",
       "  'cancer',\n",
       "  'deaths',\n",
       "  'among',\n",
       "  'a',\n",
       "  'group',\n",
       "  'of',\n",
       "  'workers',\n",
       "  'exposed',\n",
       "  'to',\n",
       "  'it',\n",
       "  'more',\n",
       "  'than',\n",
       "  'N',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'researchers',\n",
       "  'reported']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看前5筆\n",
    "raw_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3502,
     "status": "ok",
     "timestamp": 1606320765980,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "3oki6AxhJyj4",
    "outputId": "79a06d23-2176-4600-b55b-033dfb81ce49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subsampling: 885720 words\n",
      "After subsampling: 449166 words\n"
     ]
    }
   ],
   "source": [
    "# 定義資料前處理函示\n",
    "class PreProcessor():\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    min_freq: int\n",
    "        minimum frequency of a word to be kept\n",
    "    do_subsampling: bool\n",
    "        whether to do subsampling\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, only_word: bool=False, min_freq: int=5, do_subsampling: bool=True, t: float=1e-5):\n",
    "        self.only_word = only_word\n",
    "        self.min_freq = min_freq\n",
    "        self.do_subsampling = do_subsampling\n",
    "        self.t = t\n",
    "    \n",
    "    def process(self, corpus: List[str]):\n",
    "        \n",
    "        word_dic = set()\n",
    "        counter = Counter()\n",
    "        processed_sentence = []\n",
    "        \n",
    "        for sentence in corpus:\n",
    "        \n",
    "            # hint: 請計算字詞頻率\n",
    "            counter.update(sentence)\n",
    "            processed_sentence.append(sentence)\n",
    "    \n",
    "        # hint: 移除頻率過小的字詞 建立word2idx與idx2word與word_frequency辭典\n",
    "        word_cnt = dict(filter(lambda x:x[1]>self.min_freq, counter.items()))\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(word_cnt.keys())}\n",
    "        self.idx2word ={idx: word for word, idx in self.word2idx.items()}\n",
    "        self.word_frequency = word_cnt.copy()\n",
    "        \n",
    "        #將文本轉為ID型式與移除文本中頻率過小的文字\n",
    "        self.processed_corpus = [[self.word2idx[word] for word in line if word in self.word2idx] for line in processed_sentence]\n",
    "        self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
    "        print(f\"Before subsampling: {self.total_num_words} words\")\n",
    "        \n",
    "        # 進行二次採樣(subsampling)\n",
    "        if self.do_subsampling:\n",
    "            self.processed_corpus = [[idx for idx in line if not self.subsampling(idx)] for line in self.processed_corpus]\n",
    "            self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
    "            counter = Counter([self.idx2word[idx] for line in self.processed_corpus for idx in line])\n",
    "            self.word_frequency = dict(counter.items())\n",
    "            print(f\"After subsampling: {self.total_num_words} words\")\n",
    "        \n",
    "        # hint: 移除空字串\n",
    "        self.processed_corpus = [line for line in self.processed_corpus if len(line) != 0]\n",
    "        \n",
    "        return self.processed_corpus, self.word2idx, self.idx2word, self.word_frequency, self.total_num_words\n",
    "\n",
    "    def subsampling(self, idx):\n",
    "        \n",
    "        # hint: 學員可以參考講義的subsampling公式(也可自己定義一個)\n",
    "        \n",
    "        p = self.t / self.word_frequency[self.idx2word[idx]] * self.total_num_words\n",
    "        p_w = math.sqrt(p) + p\n",
    "        return random.uniform(0, 1) < p_w\n",
    "\n",
    "\n",
    "# 進行資料前處理\n",
    "# 這邊我們subsampling的t取1e-4\n",
    "pre_processor = PreProcessor(True, 5, True, 1e-4)\n",
    "corpus, word2idx, idx2word, word2freq, total_num_words = pre_processor.process(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfDuJuT5Kkvl"
   },
   "source": [
    "### 定義Skip-gram使用的Dataset與collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 客製化Dataset\n",
    "class SkipGramGetAllDataset(Dataset):\n",
    "    def __init__(self, corpus, word2freq, word2idx, idx2word, window_size, num_negatives):\n",
    "        self.corpus = corpus\n",
    "        self.word2freq = word2freq\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.window_size = window_size\n",
    "        self.num_negatives = num_negatives\n",
    "        \n",
    "        self.all_targets, self.all_contexts = self._get_all_contexts_targets()\n",
    "        self.all_negatives = self._get_all_negatives()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # hint: 這裡我們會返回 目標字詞，上下文，負採樣樣本\n",
    "        return (self.all_targets[idx], self.all_contexts[idx], self.all_negatives[idx])\n",
    "        \n",
    "    def _get_all_contexts_targets(self):\n",
    "        all_targets = []\n",
    "        all_contexts = []\n",
    "        \n",
    "        for line in self.corpus:\n",
    "            if len(line) < 2 * self.window_size + 1:\n",
    "                continue\n",
    "            \n",
    "            # hint: 這邊我們要創建上下文(考慮window_size)\n",
    "            all_contexts += line[self.window_size:-self.window_size]\n",
    "\n",
    "            targets = []\n",
    "            for idx in range(self.window_size, len(line) - self.window_size):\n",
    "                # hint: 創建目標字詞\n",
    "                indices = list(range(idx - self.window_size, idx + self.window_size + 1))\n",
    "                indices.remove(idx)\n",
    "                all_targets.append([line[i] for i in indices])\n",
    "\n",
    "        return all_targets, all_contexts\n",
    "                               \n",
    "    \n",
    "    def _get_all_negatives(self):\n",
    "        # hint: 進行負採樣，若沒頭緒的學員可以參考實作範例\n",
    "        cur_exists_words = list(self.word2freq.keys())\n",
    "        sampling_weights = [self.word2freq[word] ** 0.75 for word in self.word2freq]\n",
    "        population = list(range(len(sampling_weights)))\n",
    "        \n",
    "        all_negatives = []\n",
    "        for targets in self.all_targets:\n",
    "            negatives = []\n",
    "            while len(negatives) < self.num_negatives:\n",
    "                neg_candidate = random.choices(population, sampling_weights)[0]\n",
    "                neg_cnadidate = self.word2idx[cur_exists_words[neg_candidate]]\n",
    "                if neg_candidate not in targets:\n",
    "                    negatives.append(neg_candidate)\n",
    "            all_negatives.append(negatives)\n",
    "        \n",
    "        return all_negatives\n",
    "    \n",
    "# 客製化collate_fn\n",
    "def skipgram_collate(data):\n",
    "    contexts = []\n",
    "    target_negative = []\n",
    "    labels = []\n",
    "    for target, context, negative in data:\n",
    "        # hint: 將目標字詞、上下文與負採樣樣本個別打包\n",
    "        target_negative += [target + negative]\n",
    "        labels += [[1] * len(target) + [0] * len(negative)]\n",
    "        contexts += [context]\n",
    "    \n",
    "    return torch.tensor(contexts), torch.tensor(target_negative), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s94kJ0lKKzG5"
   },
   "source": [
    "### 定義Skip-gram模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1606320766292,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "kyyQyLxcKpv1"
   },
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        \n",
    "        self.in_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.out_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "    def forward(self, contexts, targets):\n",
    "        v = self.in_embedding(contexts)\n",
    "        u = self.out_embedding(targets)\n",
    "        \n",
    "        # do dot product to get output\n",
    "        pred = torch.matmul(v.unsqueeze(1), u.permute(0,2,1))\n",
    "        \n",
    "        return pred.squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHZIFz7yK5An"
   },
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 13745,
     "status": "ok",
     "timestamp": 1606320780465,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "Hr4sVBd8K10T"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "verbose = True\n",
    "num_epochs = 20\n",
    "batch_size = 512\n",
    "embed_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "model = SkipGram(len(word2idx), embed_size)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "dataset = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, 1, 5)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=skipgram_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219482,
     "status": "ok",
     "timestamp": 1606321001876,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "sE28LW2_LB0I",
    "outputId": "4cf7c434-b5b8-4e73-eb3c-c2735ef0d17c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Batch: 501/715.779296875 Loss: 0.67847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:22<07:10, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Loss: 0.55976\n",
      "Epoch: 2/20, Batch: 501/715.779296875 Loss: 0.25218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:48<07:05, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20, Loss: 0.24999\n",
      "Epoch: 3/20, Batch: 501/715.779296875 Loss: 0.23675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [01:11<06:36, 23.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20, Loss: 0.23696\n",
      "Epoch: 4/20, Batch: 501/715.779296875 Loss: 0.23192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [01:38<06:31, 24.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20, Loss: 0.23231\n",
      "Epoch: 5/20, Batch: 501/715.779296875 Loss: 0.22895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [02:02<06:07, 24.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20, Loss: 0.22962\n",
      "Epoch: 6/20, Batch: 501/715.779296875 Loss: 0.22735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [02:28<05:48, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20, Loss: 0.22776\n",
      "Epoch: 7/20, Batch: 501/715.779296875 Loss: 0.22633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [02:52<05:20, 24.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20, Loss: 0.22638\n",
      "Epoch: 8/20, Batch: 501/715.779296875 Loss: 0.22480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [03:16<04:53, 24.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20, Loss: 0.22533\n",
      "Epoch: 9/20, Batch: 501/715.779296875 Loss: 0.22423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [03:40<04:27, 24.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20, Loss: 0.22473\n",
      "Epoch: 10/20, Batch: 501/715.779296875 Loss: 0.22384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [04:04<04:02, 24.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20, Loss: 0.22413\n",
      "Epoch: 11/20, Batch: 501/715.779296875 Loss: 0.22317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [04:28<03:37, 24.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20, Loss: 0.22367\n",
      "Epoch: 12/20, Batch: 501/715.779296875 Loss: 0.22311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [04:52<03:12, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20, Loss: 0.22354\n",
      "Epoch: 13/20, Batch: 501/715.779296875 Loss: 0.22283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [05:16<02:47, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20, Loss: 0.22330\n",
      "Epoch: 14/20, Batch: 501/715.779296875 Loss: 0.22244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [05:40<02:23, 24.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20, Loss: 0.22316\n",
      "Epoch: 15/20, Batch: 501/715.779296875 Loss: 0.22303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [06:04<01:59, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20, Loss: 0.22308\n",
      "Epoch: 16/20, Batch: 501/715.779296875 Loss: 0.22265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [06:28<01:35, 23.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/20, Loss: 0.22293\n",
      "Epoch: 17/20, Batch: 501/715.779296875 Loss: 0.22240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [06:53<01:13, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20, Loss: 0.22290\n",
      "Epoch: 18/20, Batch: 501/715.779296875 Loss: 0.22219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [07:18<00:48, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20, Loss: 0.22276\n",
      "Epoch: 19/20, Batch: 501/715.779296875 Loss: 0.22182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [07:42<00:24, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20, Loss: 0.22276\n",
      "Epoch: 20/20, Batch: 501/715.779296875 Loss: 0.22224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [08:06<00:00, 24.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20, Loss: 0.22271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "lst_loss = []\n",
    "model.train()\n",
    "for epc in tqdm.tqdm(range(num_epochs)):\n",
    "    batch_loss = 0\n",
    "\n",
    "    for i, (contexts, target_negative, labels) in enumerate(loader, 1):\n",
    "        # hint: 開始訓練前要先將optimizer的梯度歸零\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_cuda:\n",
    "            contexts = contexts.cuda()\n",
    "            target_negative = target_negative.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        pred = model(contexts, target_negative)\n",
    "        loss = criterion(pred, labels.float())\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(f\"Epoch: {epc + 1}/{num_epochs}, Batch: {i+1}/{len(dataset)/batch_size} Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Epoch: {epc + 1}/{num_epochs}, Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "    lst_loss.append(batch_loss/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1606321013487,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "y0rt5W2ELLvP",
    "outputId": "b497edcc-fc8e-47d3-b3ff-c574d42ff581"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFNCAYAAABFbcjcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvdklEQVR4nO3de5glVX3v//e3u2e6G+ayB2cQds8gKJgTvIGZkAvRcKIomgRINBGNCprEx0RO9JiTI/z0pwb1BDUxJr9g1Ci/YLxgolHHCEFJvAQTlEFHDShhuChzQQYY5sLc+vI9f1R1956e3T3dPbt67+l+v55nP3vXqlVVq6r3dH9mVdWqyEwkSZLUGbra3QBJkiSNM5xJkiR1EMOZJElSBzGcSZIkdRDDmSRJUgcxnEmSJHUQw5mkloiIt0bER9vdjumKiHsj4tmTzLstIs6Z2xYdXSIiI+LUadQ7JyI2zUWbpPnCcCbNUxFxeURcP6HszknKLmrxtp8YEZ+LiG0R8XBE3BARP1HOu6gMRjFhmZ6IeCAifqVFbVgcEX8WEZsiYne5zfdOZ9nMfFJmfqUV7Wi3iPhKGaSeNqH8M2X5Oe1pmaTJGM6k+etrwM9HRDdARJwILALOnFB2all32iKi5zBVasA64CeAxwLfBD5XzvtsOf8XJyxzHpDAP8+kLVO4HFgLnAUsBc4BvtWidbfENI5jq/wX8PKG7T4G+Dlg2xxtX9IMGM6k+esWijB2Rjn9DODLwB0Tyu7KzC0RUY+IdWVP18aI+N3RFZWnLD8VER+NiJ3AJRFxSkR8NSJ2RcSXgJWj9TPzm5n54cx8ODMHgT8HfiIiHpOZ+4C/pyEslF4OfDwzhyLiZyPi3yPikYj4TmPvTkQcFxH/f0RsiYjtEfHZSfb/p4HPZOaWLNybmR9pVjEifjIi7omIF5fTY6c8G/b9k+W+fmtiL9SEdfVHxDVl274fEf+78bReue43RMR3gUfLHsPLIuKucv23R8SvNdS/JCK+HhF/Xh6PuyPi58vy+8rexosna0/pY8CLRkM58GLgM8CBhu30RsR7y+O6pfzc2zD/jyJiaznvlRP2uTci/jQifhQRP46I90dE/2HaJGkShjNpnsrMA8A3gGeWRc8E/g24aULZaK/ZtcAmoA68EPg/EfFLDau8APgURa/Xx4CPA7dShLK3AVMFhGcC92fmQ+X0NcALR/+AR8Ry4FeBayJiAPgC8HbgOOB/AZ+OiFXlsn8HHAM8CTieIvg1czPw+oj4/Yh4ysTTqKMi4unADcD/yMxPTLKuC4B/KNvzceCzEbFokrpvAU4GHg+cC7y0SZ0XA78M1DJzCLiLIigvB/4Y+GjZqznqZ4DvAo8pt38tRfg8tVz/X0XEkknaA7AFuB14Tjn9cmBiUH0j8LMUwf1pFD2ObwKIiPMofg7nAqcBE6/VuxJ4YrnsqcAA8OYp2iNpKpnpy5evefoC3krRewTwHYo/rOdNKLsYWAMMA0sblv0T4G8b1vO1hnknAUPAsQ1lHwc+2qQNq4HNwIsnlN8JvKT8/LvAd8rPbwD+bkLdG8p2ngiMACumse/dwGuArwP7KQLKxQ3z76UIQpuAcyYsey/w7IZ9v7lhXhewFXjGJNu9G3huw/TvAJsmrPuVh2n7BuCC8vMlwJ0N855Ccfr3sQ1lDwFnTLKur5RteCnwCeC/Af9Vzhvbd4qA+PyG5Z4L3Ft+vhq4smHeE8s2nAoE8CjwhIb5PwfcU34+p3H/ffnydfiXPWfS/PY14Bci4jhgVWbeCfw7xbVoxwFPLuvUgYczc1fDsj+k6AEZdV/D5zqwPTMfnVD/IGVv1xeB9+WhvVIfYfzU5ssY78l5HPAb5Sm8RyLiEeAXKILZmrKd2w+345k5nJlXZebZFL197wCujoifbKj2auDf8/AX/4/te2aOUPYwRsRvlTcb7I7xGy3qHHysGj83LYuIl0fEhob9fTINp4mBHzd83lu2Y2LZVD1nAP8I/BJwKUXv40R1Dv4Z/rAsG51334R5o1ZR9GTe2tD+fy7LJc2C4Uya3/6D4lTZ71L0IJGZOyl6kX4X2JKZ95TTx0XE0oZlT6Lo8RqVDZ+3Aisi4tgJ9cdExAqKYLYuM9/RpG1/BzwrIn6O4nTax8ry+yh6zmoNr2Mz88py3nERUZv2ESj2eW9mXgVsB05vmPVq4KSImOzU6Kg1DfvVRdEbuCUzP5aZS8rX88oqW8v5hyzb2KSG9T0O+BuK0PSYzKwB/0nRI9UymbkHuB74PZqHsy0UwXjUSWUZFPu0ZsK8UQ9ShMMnNfy8lmfm4cKipEkYzqR5LDP3AuuB11NcbzbqprLsa2W9+yh61P4kIvoi4qnAbwNNxy3LzB+W6/3jKIas+AWKa8YAiIhlFKciv56Zl02yjnvLdnwC+FJm3l/O+ijwqxHx3IjoLttzTkSszsytFAHjfRGxIiIWRcQzm60/Il5XLtdfXnR/McVdm99uqLaL4jTvMyPiymbrKf1URPx6FHdXvo7iNOnNk9T9e+Dysn0DFKFrKsdShLVtZbtfQdFzVoX/B/jF8thP9AngTRGxKiJWUlwzNvrz/3uKm0BOj4hjKK6rA8Z6Ev8G+POIOL7ch4GIeG5F+yDNe4Yzaf77KsWF8zc1lP1bWdY4hMaLKS5k30JxJ99bMvPGKdb7EooL1R+m+GPdeIH5r1FcsP6KhtN+uyPipAnruIait2Zs2TIoXkARJLZR9Jb9EeO/r14GDAI/AB6gCEvN7AH+DLifonfnNcALMvPuxkqZ+QjFhe7Pi4i3TbKuzwEvouh5exnw61nchdrMFRSnPe8BbqS4iWL/JHXJzNvLdv4HxenLp1D2crZaFneu3jTJ7LdTBO7vAt+jGHbk7eVy1wPvBf4V2Fi+N3pDWX5zFHfz3kgxjIqkWYjMPHwtSVqgIuKtwKmZ2eyuy+ks/3vARZk5cVw3SWrKnjNJaqGIODEizo6IriieivCHFD2RkjQtczU6tSQtFIuBDwCnAI9QjEn2vnY2SNLRxdOakiRJHcTTmpIkSR3EcCZJktRB5s01ZytXrsyTTz653c2QJEk6rFtvvfXBzGz6JI15E85OPvlk1q9f3+5mSJIkHVZEHPLIu1Ge1pQkSeoghjNJkqQOYjiTJEnqIIYzSZKkDmI4kyRJ6iCGM0mSpA5iOJMkSeog82acsyqtffuXeHD3gUPKVy5ZzPo3nduGFkmSpPnKnrNpaBbMpiqXJEmaLcOZJElSBzGcSZIkdRDDmSRJUgcxnEmSJHUQw9k0rFyyeEblkiRJs1XpUBoRcR7wF0A38KHMvHLC/EuAdwOby6K/yswPlfOGge+V5T/KzPOrbOtURofL+MBX7+JPrv8B333rc1jWt6hdzZEkSfNYZeEsIrqBq4BzgU3ALRGxLjNvn1D1k5l5aZNV7M3MM6pq32zUa/0AbH1kH8tOMJxJkqTWq/K05lnAxsy8OzMPANcCF1S4vcqNhrPNj+xpc0skSdJ8VWU4GwDua5jeVJZN9IKI+G5EfCoi1jSU90XE+oi4OSIurLCd0zYwFs72tbklkiRpvmr3DQGfB07OzKcCXwKuaZj3uMxcC7wEeG9EPGHiwhHxqjLArd+2bVvljV21tJeermDLI3sr35YkSVqYqgxnm4HGnrDVjF/4D0BmPpSZ+8vJDwE/1TBvc/l+N/AV4MyJG8jMD2bm2sxcu2rVqta2vonuruDEWp/hTJIkVabKcHYLcFpEnBIRi4GLgHWNFSLixIbJ84Hvl+UrIqK3/LwSOBuYeCNBW9SX9xvOJElSZSq7WzMzhyLiUuAGiqE0rs7M2yLiCmB9Zq4D/iAizgeGgIeBS8rFfxL4QESMUATIK5vc5dkWA7V+vnHPw+1uhiRJmqcqHecsM68DrptQ9uaGz5cDlzdZ7t+Bp1TZttmq1/q5f+c+hoZH6Olu9yV7kiRpvjFdzFC91s/wSPLArv2HryxJkjRDhrMZqtf6ALzuTJIkVcJwNkPjY50ZziRJUusZzmboxDKcbXEgWkmSVAHD2Qwt6e1hef8iH+EkSZIqYTibhXqt354zSZJUCcPZLAzUHIhWkiRVw3A2CwO1Pm8IkCRJlTCczUK91s+ufUPs3DfY7qZIkqR5xnA2C/Xyjs2tXncmSZJazHA2C/Wx4TQ8tSlJklrLcDYLDkQrSZKqYjibhVVLe+npCnvOJElSyxnOZqG7KzhheZ/hTJIktZzhbJbqtX5Pa0qSpJYznM3SgE8JkCRJFTCczVK91sf9O/cxNDzS7qZIkqR5xHA2SwO1YxgeSR7Ytb/dTZEkSfOI4WyW6rU+wLHOJElSaxnOZsmxziRJUhUMZ7N04thTArwpQJIktY7hbJaW9PawvH+RpzUlSVJLGc6OQL3WbziTJEktZTg7AgO1Pq85kyRJLWU4OwI+JUCSJLWa4ewI1Gv97No3xM59g+1uiiRJmicMZ0egXt6xudU7NiVJUotUGs4i4ryIuCMiNkbEZU3mXxIR2yJiQ/n6nYZ5F0fEneXr4irbOVsDY8NpeGpTkiS1Rk9VK46IbuAq4FxgE3BLRKzLzNsnVP1kZl46YdnjgLcAa4EEbi2X3V5Ve2fDgWglSVKrVdlzdhawMTPvzswDwLXABdNc9rnAlzLz4TKQfQk4r6J2ztqqpb30dIU9Z5IkqWWqDGcDwH0N05vKsoleEBHfjYhPRcSaGS7bVt1dwQnL+wxnkiSpZdp9Q8DngZMz86kUvWPXzGThiHhVRKyPiPXbtm2rpIGHUwxE6w0BkiSpNaoMZ5uBNQ3Tq8uyMZn5UGbuLyc/BPzUdJctl/9gZq7NzLWrVq1qWcNnYsCxziRJUgtVGc5uAU6LiFMiYjFwEbCusUJEnNgweT7w/fLzDcBzImJFRKwAnlOWdZx6rY/7d+5jeCTb3RRJkjQPVHa3ZmYORcSlFKGqG7g6M2+LiCuA9Zm5DviDiDgfGAIeBi4pl304It5GEfAArsjMh6tq65Go1/oZHkke2LWPE5f3t7s5kiTpKFdZOAPIzOuA6yaUvbnh8+XA5ZMsezVwdZXta4XRgWg3b99rOJMkSUes3TcEHPUc60ySJLWS4ewI1ceeEuAdm5Ik6cgZzo7Qkt4elvcvcqwzSZLUEoazFijGOjOcSZKkI2c4a4GBWp/XnEmSpJYwnLWAPWeSJKlVDGctUK/1s3PfELv2Dba7KZIk6ShnOGuB0Ts2t+7wjk1JknRkDGctMFDrAxzrTJIkHTnDWQs0PiVAkiTpSBjOWuD4pX10d4U3BUiSpCNmOGuB7q7ghGV9hjNJknTEDGctMrCi30c4SZKkI2Y4a5GBWr83BEiSpCNmOGuReq2P+3fuY3gk290USZJ0FDOctUi91s/wSPLALk9tSpKk2TOctcjocBreFCBJko6E4axFBkbHOvOmAEmSdAQMZy1y4vLiKQH2nEmSpCNhOGuRpX2LWNbX41MCJEnSETGctVC91m/PmSRJOiKGsxZyrDNJknSkDGctVDwlwHAmSZJmz3DWQvVaPzv3DbFr32C7myJJko5ShrMWGh3rbOsOh9OQJEmzYzhroYFaMZyG151JkqTZMpy1kE8JkCRJR8pw1kLHL+2juysMZ5IkadYqDWcRcV5E3BERGyPisinqvSAiMiLWltMnR8TeiNhQvt5fZTtbpbsrOGFZH1t8hJMkSZqlnqpWHBHdwFXAucAm4JaIWJeZt0+otxR4LfCNCau4KzPPqKp9VXGsM0mSdCSq7Dk7C9iYmXdn5gHgWuCCJvXeBrwTmBfdTfVan49wkiRJs1ZlOBsA7muY3lSWjYmIpwNrMvMLTZY/JSK+HRFfjYhnVNjOlqrX+rl/5z6GR7LdTZEkSUehyk5rHk5EdAHvAS5pMnsrcFJmPhQRPwV8NiKelJk7J6zjVcCrAE466aSKWzw9Ayv6GR5JHti1jxOX97e7OZIk6ShTZc/ZZmBNw/TqsmzUUuDJwFci4l7gZ4F1EbE2M/dn5kMAmXkrcBfwxIkbyMwPZubazFy7atWqinZjZhxOQ5IkHYkqw9ktwGkRcUpELAYuAtaNzszMHZm5MjNPzsyTgZuB8zNzfUSsKm8oICIeD5wG3F1hW1tmoAxnm71jU5IkzUJlpzUzcygiLgVuALqBqzPztoi4AlifmeumWPyZwBURMQiMAK/OzIeramsrnbi8eEqAPWeSJGk2Kr3mLDOvA66bUPbmSeqe0/D508Cnq2xbVZb2LWJZX4/hTJIkzYpPCKhAvdZvOJMkSbNiOKtAMRCt15xJkqSZM5xVwJ4zSZI0W4azCtRr/ezYO8ju/UPtbookSTrKGM4qUK95x6YkSZodw1kFxsc6M5xJkqSZMZxVYGCFTwmQJEmzYzirwPFL++juCsOZJEmaMcNZBbq7ghOW9bHF4TQkSdIMGc4qUox1Zs+ZJEmaGcNZReq1Pk9rSpKkGTOcVaRe6+f+HfsYHsl2N0WSJB1FDGcVqdf6GRpJtu3a3+6mSJKko4jhrCLjY53taXNLJEnS0cRwVpH6WDjzjk1JkjR9hrOK+AgnSZI0G4aziiztW8Syvh7DmSRJmhHDWYXqtX7DmSRJmhHDWYWKgWi95kySJE2f4axC9pxJkqSZMpxVqF7rZ8feQXbvH2p3UyRJ0lHCcFah0Ts2t9p7JkmSpslwVqHxgWgNZ5IkaXoMZxUaHYh2izcFSJKkaTKcVej4pb10d4WPcJIkSdNmOKtQT3cXJyzrs+dMkiRNm+GsYsVYZ15zJkmSpsdwVrF6rc+xziRJ0rRVGs4i4ryIuCMiNkbEZVPUe0FEZESsbSi7vFzujoh4bpXtrFK91s/9O/YxPJLtbookSToKVBbOIqIbuAp4HnA68OKIOL1JvaXAa4FvNJSdDlwEPAk4D3hfub6jTr3Wz9BIsm3X/nY3RZIkHQWq7Dk7C9iYmXdn5gHgWuCCJvXeBrwTaLxq/gLg2szcn5n3ABvL9R11HOtMkiTNxLTCWUS8NiKWReHDEfGtiHjOYRYbAO5rmN5UljWu9+nAmsz8wkyXLZd/VUSsj4j127Ztm86uzLnxsc4MZ5Ik6fCm23P2yszcCTwHWAG8DLjySDYcEV3Ae4A/nO06MvODmbk2M9euWrXqSJpTmdFHOBnOJEnSdPRMs16U788H/i4zb4uImGoBYDOwpmF6dVk2ainwZOAr5apOANZFxPnTWPaosbRvEUv7egxnkiRpWqbbc3ZrRHyRIpzdUF7EP3KYZW4BTouIUyJiMcUF/utGZ2bmjsxcmZknZ+bJwM3A+Zm5vqx3UUT0RsQpwGnAN2e0Zx3Esc4kSdJ0Tbfn7LeBM4C7M3NPRBwHvGKqBTJzKCIuBW4AuoGryx63K4D1mbluimVvi4i/B24HhoDXZObwNNvaceq1fjb7lABJkjQN0w1nPwdsyMxHI+KlwNOBvzjcQpl5HXDdhLI3T1L3nAnT7wDeMc32dbR6rY9bf7i93c2QJElHgeme1vxrYE9EPI3iAv67gI9U1qp5ZqB2DDv2DrJ7/1C7myJJkjrcdMPZUGYmxfhjf5WZV1Fc0K9pGL1jc6vXnUmSpMOYbjjbFRGXUwyh8YVyGIxF1TVrfnEgWkmSNF3TDWcvAvZTjHd2P8XQFu+urFXzzPhAtN4UIEmSpjatcFYGso8ByyPiV4B9mek1Z9N0/NJeurvCsc4kSdJhTffxTb9JMc7YbwC/CXwjIl5YZcPmk57uLk5Y1mc4kyRJhzXdoTTeCPx0Zj4AEBGrgBuBT1XVsPmmXuvzmjNJknRY073mrGs0mJUemsGyYnQgWsOZJEma2nQD1j9HxA0RcUlEXAJ8gQmDy2pq9Vo/9+/Yx/BItrspkiSpg03rtGZm/lFEvAA4uyz6YGZ+prpmzT/1Wj9DI8m2Xfs5YXlfu5sjSZI61HSvOSMzPw18usK2zGurG8Y6M5xJkqTJTHlaMyJ2RcTOJq9dEbFzrho5H4yPdeZ1Z5IkaXJT9pxlpo9oapHRRzgZziRJ0lS843KOLO1bxNK+HsOZJEmakuFsDg3U+tnsI5wkSdIUDGdzqF7rt+dMkiRNyXA2h+q1PrbsMJxJkqTJGc7mUL3WzyN7Bnl0/1C7myJJkjqU4WwODTichiRJOgzD2RyqNwxEK0mS1IzhbA6N95x5x6YkSWrOcDaHjl/aS3dXeFpTkiRNynA2h3q6uzhhWZ/hTJIkTcpwNsfqtT6vOZMkSZMynM2xeq3fsc4kSdKkDGdzrF7r5/4d+xgeyXY3RZIkdSDD2Ryr1/oZHE4e3L2/3U2RJEkdqNJwFhHnRcQdEbExIi5rMv/VEfG9iNgQETdFxOll+ckRsbcs3xAR76+ynXNpoNYHONaZJElqrrJwFhHdwFXA84DTgRePhq8GH8/Mp2TmGcC7gPc0zLsrM88oX6+uqp1zbWwg2u2GM0mSdKgqe87OAjZm5t2ZeQC4FrigsUJm7myYPBaY9xdi1X2EkyRJmkKV4WwAuK9helNZdpCIeE1E3EXRc/YHDbNOiYhvR8RXI+IZFbZzTi3rW8TS3h7DmSRJaqrtNwRk5lWZ+QTgDcCbyuKtwEmZeSbweuDjEbFs4rIR8aqIWB8R67dt2zZ3jT5CAyv62ewjnCRJUhNVhrPNwJqG6dVl2WSuBS4EyMz9mflQ+flW4C7giRMXyMwPZubazFy7atWqVrW7cvVavz1nkiSpqSrD2S3AaRFxSkQsBi4C1jVWiIjTGiZ/GbizLF9V3lBARDweOA24u8K2zql6rc+BaCVJUlM9Va04M4ci4lLgBqAbuDozb4uIK4D1mbkOuDQing0MAtuBi8vFnwlcERGDwAjw6sx8uKq2zrV6rZ9H9gzy6P4hju2t7EcgSZKOQpUmg8y8DrhuQtmbGz6/dpLlPg18usq2tdNAecfm1h17OfX4pW1ujSRJ6iRtvyFgIRob68ybAiRJ0gSGszZwrDNJkjQZw1kbPHZpL13hUwIkSdKhDGdt0NPdxQnL+uw5kyRJhzCctUm91u/DzyVJ0iEMZ20ysKLfsc4kSdIhDGdtUq/1c/+OfQyPzPtnvUuSpBkwnLVJvdbP4HDy4O797W6KJEnqIIazNhmo9QF43ZkkSTqI4axNHOtMkiQ1YzhrE8OZJElqxnDWJsv6FrG0t4ctPsJJkiQ1MJy1kWOdSZKkiQxnbVSv9fkIJ0mSdBDDWRvVaw5EK0mSDmY4a6OBFf08smeQR/cPtbspkiSpQxjO2migvGNzq71nkiSpZDhro9HhNDZ7x6YkSSoZztrIsc4kSdJEhrM2euzSXrrCcCZJksYZztqop7uLE5b1OdaZJEkaYzhrs3qt354zSZI0xnDWZkU484YASZJUMJy1Wb3Wz9YdexkZyXY3RZIkdQDDWZsN1PoYHE627d7f7qZIkqQOYDhrs/GxzrzuTJIkGc7abmCFY51JkqRxhrM2cyBaSZLUqNJwFhHnRcQdEbExIi5rMv/VEfG9iNgQETdFxOkN8y4vl7sjIp5bZTvbaVnfIpb29njHpiRJAioMZxHRDVwFPA84HXhxY/gqfTwzn5KZZwDvAt5TLns6cBHwJOA84H3l+ualeq3fa84kSRJQbc/ZWcDGzLw7Mw8A1wIXNFbIzJ0Nk8cCo+NJXABcm5n7M/MeYGO5vnmpXuvztKYkSQKqDWcDwH0N05vKsoNExGsi4i6KnrM/mMmy84VPCZAkSaPafkNAZl6VmU8A3gC8aSbLRsSrImJ9RKzftm1bNQ2cA/VaP9v3DLLnwFC7myJJktqsynC2GVjTML26LJvMtcCFM1k2Mz+YmWszc+2qVauOrLVtNOAdm5IkqVRlOLsFOC0iTomIxRQX+K9rrBARpzVM/jJwZ/l5HXBRRPRGxCnAacA3K2xrW40PROsdm5IkLXQ9Va04M4ci4lLgBqAbuDozb4uIK4D1mbkOuDQing0MAtuBi8tlb4uIvwduB4aA12TmcFVtbbd6rQ+w50ySJFUYzgAy8zrgugllb274/Nopln0H8I7qWtc5TljWR1cYziRJUgfcECDo6e7ihGV9jnUmSZIMZ53C4TQkSRIYzjpGEc68IUCSpIXOcNYh6rV+tu7Yy8hIHr6yJEmatwxnHWKg1sfgcPLg7v3tbookSWojw1mHGB/rzOvOJElayAxnHaI+9pQArzuTJGkhM5x1iPGesz1tbokkSWonw1mHWNbXw5LeHnvOJEla4AxnHSIiGKj1e82ZJEkLnOGsg9RrfQ5EK0nSAmc46yA+JUCSJBnOOki91s/2PYPsOTDU7qZIkqQ2MZx1kAGH05AkacEznHWQ8bHOPLUpSdJCZTjrIPVaH2A4kyRpITOcdZDHLuujKwxnkiQtZIazDrKou4vHLutjk+FMkqQFy3DWYRxOQ5Kkhc1w1mGKcObdmpIkLVSGsw4zUOtn6469jIxku5siSZLawHDWYQZqfQwOJw/u3t/upkiSpDYwnHWY0bHOfAC6JEkLk+Gsw9R9SoAkSQua4azD+JQASZIWNsNZh1nW18OS3h5Pa0qStEAZzjpMRFCv9dlzJknSAmU460D1Wr89Z5IkLVA9Va48Is4D/gLoBj6UmVdOmP964HeAIWAb8MrM/GE5bxj4Xln1R5l5fpVt7RRr3/4lHtx9AICTL/vCWPnKJYtZ/6Zz29UsSZI0RyoLZxHRDVwFnAtsAm6JiHWZeXtDtW8DazNzT0T8HvAu4EXlvL2ZeUZV7etUo8FsuuWSJGl+qfK05lnAxsy8OzMPANcCFzRWyMwvZ+aecvJmYHWF7ZEkSep4VYazAeC+hulNZdlkfhu4vmG6LyLWR8TNEXFhswUi4lVlnfXbtm074gZLkiS1W0fcEBARLwXWAu9uKH5cZq4FXgK8NyKeMHG5zPxgZq7NzLWrVq2ao9a2z1s+9598+0fbyfS5m5IkzVdV3hCwGVjTML26LDtIRDwbeCPwi5k59kDJzNxcvt8dEV8BzgTuqrC9He8Tt9zHNf/xQ05+zDFccMYAF545wCkrj213syRJUgtV2XN2C3BaRJwSEYuBi4B1jRUi4kzgA8D5mflAQ/mKiOgtP68EzgYabySYt1YuWTxp+fo3PZt3vfCp1Gv9/OW/3sl//9OvcMFVX+dvv36PD0qXJGmeiCpPkUXE84H3UgylcXVmviMirgDWZ+a6iLgReAqwtVzkR5l5fkT8PEVoG6EIkO/NzA9Pta21a9fm+vXrq9qVjrN1x14+/50tfObbW/j+1p10dwXPOG0lv3bmAOee/liOWVzpKCmSJOkIRMSt5eVbh86bL9cvLbRw1uiO+3fx2Q2bWbdhC5sf2csxi7t57pNO4MIzBzj7CY+hp7sjLi2UJEklw9kCMTKS3HLvw3x2w2a+8N2t7Nw3xMolvfzq007kwjMGeOrq5UREu5spSdKCZzhbgPYPDfPlH2zjcxs28y/ff4ADwyM8fuWxXHjmABeeMcCv//XXmw5s65MIJEmqnuFsgduxd5Drv7eVz27YzM13P3zY+vde+ctz0CpJkhauqcKZV40vAMv7F3HRWSdx0VknseWRvaz7zhauvP4Hk9b/9o+2s3rFMaxcstjToJIkzTF7zhaoxoeqT6Z/UTerV/SzekU/a447hjUrjjno87L+nmmFt8aHuTfyFKokaaGy50wz8uGL13Lfw3u4b/teNm3fw30P72X9D7eza9/QQfWW9vaw+rhjWLOin9UrjmHNcf1FgCvfj+0tvl4+zF2SpOkznOkQz/rJxzYt37FnkPu27xkLbJu2FwHungcf5d/ufJC9g8MH1T/u2MWsXtE/5baGhkdaOtSHvXSSpKOd4WyBWrlk8aQhZjLLj1nE8mOW8+SB5YfMy0weevTAIT1um7bvmbIdp77xepb29VA7ZhErjllM7ZjFrBj7fPD72OdjF3Ps4u6mp1TtpZMkHe0MZwtUq3uRIoKVS3pZuaSXM09acdC8qa5ve92zT+ORPYNs33OA7XsGeWTPAe55cDeP7Bk85DRqo0XdQe2YxdT6Dw5wU7nv4T0c29vDsb3d9PZ0z2wHJ7CHTpJUFcOZ2up1z37ipPMGh0fYsbcIbNv3DLL90QOHBLnR6R8+tIcN9z0y5bae8a4vj31e1B1FUFvcw5LeHpb09XBsbw9Lers5dvHo54ay3oPL5rKHziAoSQuL4UyVm80pVIBF3V1jvXHTNVUv3btf+FR27x/i0f1D7N4/zKNjn4d49MAQO/YOsuWRveNl+4cYmcXNzOe8+8v0Leqmb1E3/Yu66V/cTd+irrHpxvLeni76F5fT5by+hmX6F3XPyyA4l4HTcCvpaGM4U+U65Q/gb6xdM6P6mcm+wRF2N4S10fffvmbyYVueurrGvsFh9g4Os29wmG27htg7OMzeA8X06LzZBL+Jzr7yX+ld1MXi7i56e7ro7elmcU8Xi3uK6cb3xd3d43UnWWaqIHjXtt30dAXdXcGi7i66u6Lp9HSGV5nLwGm4dVvt3NZ83Ke53NZ83KfpMJxpXpltL10zEVH0ai3uZtXS6ffe/eWLzzxsnczkwPAI+wZHirB2YJh9Q8X7aKjbNzjC3gPD/OE/fGfS9fzM449j/9AIB8rX/qFh9hwY4pG9I+wfHOHA8Pj76PzB4dmlwmf92VenVa+7DGxTBbmpvOzD3zhkmeK9i0XdB0/3NEz3TJgefZ/Kjbf/eKy93V1BV8RB090RdHUxtq7R+V0RxbYi6Ooaf58qCGZmywZ1nq/hdj5uaz7u01xuaz7u03QYzjSvdEov3eFEBL09xY0Jy/sXTVl3qnD2nt88Y8bbHhkpguH+hkB3YKgIcOe9998mXe4vLjqD4ZFkaDgZGkmGR0YYHM6ibJrTo8ve8+Cjk25n176hg5cZyYbtjozPK9c1VG5nNn7nI3M3cPUpl1839jkCguJ7EGPTRWHj9Gg9GupymHz3M//nRrqiCJAAXV2MTY+uuyui4T3oCg6dhrF1TOZlH/7GQW1rtl9l6xvmNezbhP2eyus/uWGsUnkkJhyf8Xljnydsv/h0eH/8+dsOOv5FW2N83yb7OU34eR4ui7/vKxsP2p9Gky3brHg6mf/qm+45+OczRZubfycb6h1me+u+s+XwDWqBz5fbaWxP47E8uPzQMiap2wkMZ9IstLKHbq51dQV9XcW1bTNxwRkDLWvDVL+8P/uas2e1zpGxQDce4gaHk59+x42Tt+PSsxkulxkeSYYzGRmB4SyC4fAIDI8kI1mse+SgemVZji//9i98f9JtvfZZp5EAmWTxRpLl+/g0Y9PFPOCQ+n/77/dOup1znng8STKSMFKufCTHp0fXPTLCWL3Mg99HMsfbM4Xd+4fG2t9svxibLtYNzfa73Mph8vU37314bPlRY+scmx5v88RjR0PNwz0Y51PrNx3UtqZtntD+2Txs513/fMfMF5qlK/7p9jnb1h984ttzsp3/MUfbaQfDmTQLc9lDdzQHwbnU1RUsHjuNOb3g+dTVtZa2Yapw9j/PnfzO5JmaKpy984VPbdl2YOqbbD7z+7ML0rPZ1k1v+KU529b3/vi5s17vxOB26huvn7TuD9523iTrmGTdTRJsY90nveWGSbe14c3nNg2UB/+HoHkIpcm8//6nX5l0Wze+/hcnnTdTz37P5JdT3Pj6Zx4c1hvmHVx+aChvNv+X//KmI2lqSxnOpA43H4PgXAZOw63m0ugpw3Jqyroz7b0+ErXDjAPZSqcev2SOtrN0TrbTDoYzSWPmKgjOZeA03Lqtdm5rPu7TXG5rPu7TdETO5kR5B1q7dm2uXz93F/dKkiTNVkTcmplrm81r3ROnJUmSdMQMZ5IkSR3EcCZJktRBDGeSJEkdxHAmSZLUQQxnkiRJHcRwJkmS1EEMZ5IkSR1k3gxCGxHbgB/OwaZWAg/OwXaOBh6LgsdhnMdinMdinMei4HEY57GAx2XmqmYz5k04mysRsX6yEX0XGo9FweMwzmMxzmMxzmNR8DiM81hMzdOakiRJHcRwJkmS1EEMZzP3wXY3oIN4LAoeh3Eei3Eei3Eei4LHYZzHYgpecyZJktRB7DmTJEnqIIazSUTEeRFxR0RsjIjLmszvjYhPlvO/EREnt6GZlYqINRHx5Yi4PSJui4jXNqlzTkTsiIgN5evN7WjrXIiIeyPie+V+rm8yPyLiL8vvxHcj4untaGfVIuInGn7eGyJiZ0S8bkKdefu9iIirI+KBiPjPhrLjIuJLEXFn+b5ikmUvLuvcGREXz12rW2+S4/DuiPhB+f3/TETUJll2yn9LR5tJjsVbI2Jzw7+B50+y7JR/a442kxyLTzYch3sjYsMky86r78URyUxfE15AN3AX8HhgMfAd4PQJdX4feH/5+SLgk+1udwXH4UTg6eXnpcB/NTkO5wD/1O62ztHxuBdYOcX85wPXAwH8LPCNdrd5Do5JN3A/xXg9C+J7ATwTeDrwnw1l7wIuKz9fBryzyXLHAXeX7yvKzyvavT8tPg7PAXrKz+9sdhzKeVP+WzraXpMci7cC/+swyx32b83R9mp2LCbM/zPgzQvhe3EkL3vOmjsL2JiZd2fmAeBa4IIJdS4Arik/fwp4VkTEHLaxcpm5NTO/VX7eBXwfGGhvqzraBcBHsnAzUIuIE9vdqIo9C7grM+diAOiOkJlfAx6eUNz4++Aa4MImiz4X+FJmPpyZ24EvAedV1c6qNTsOmfnFzBwqJ28GVs95w9pgku/EdEznb81RZapjUf6N/E3gE3PaqKOQ4ay5AeC+hulNHBpKxuqUv4x2AI+Zk9a1QXna9kzgG01m/1xEfCciro+IJ81ty+ZUAl+MiFsj4lVN5k/nezPfXMTkv2gXyvcC4LGZubX8fD/w2CZ1Ftr345UUPcnNHO7f0nxxaXmK9+pJTnUvtO/EM4AfZ+adk8xfKN+LwzKc6bAiYgnwaeB1mblzwuxvUZzSehrw/wGfnePmzaVfyMynA88DXhMRz2x3g9opIhYD5wP/0GT2QvpeHCSL8zML+jb4iHgjMAR8bJIqC+Hf0l8DTwDOALZSnM5b6F7M1L1mC+F7MS2Gs+Y2A2sapleXZU3rREQPsBx4aE5aN4ciYhFFMPtYZv7jxPmZuTMzd5efrwMWRcTKOW7mnMjMzeX7A8BnKE5JNJrO92Y+eR7wrcz88cQZC+l7Ufrx6Cns8v2BJnUWxPcjIi4BfgX4rTKoHmIa/5aOepn548wczswR4G9ovo8L4jsBY38nfx345GR1FsL3YroMZ83dApwWEaeUvQMXAesm1FkHjN5t9ULgXyf7RXS0Kq8P+DDw/cx8zyR1Thi91i4izqL4Ts3HkHpsRCwd/Uxx4fN/Tqi2Dnh5edfmzwI7Gk51zUeT/i94oXwvGjT+PrgY+FyTOjcAz4mIFeUprueUZfNGRJwH/G/g/MzcM0md6fxbOupNuN7012i+j9P5WzNfPBv4QWZuajZzoXwvpq3ddyR06ovizrv/oriT5o1l2RUUv3QA+ihO52wEvgk8vt1truAY/ALF6ZnvAhvK1/OBVwOvLutcCtxGcZfRzcDPt7vdFR2Lx5f7+J1yf0e/E43HIoCryu/M94C17W53hcfjWIqwtbyhbEF8LygC6VZgkOIaod+muN70X4A7gRuB48q6a4EPNSz7yvJ3xkbgFe3elwqOw0aKa6hGf1+M3tFeB64rPzf9t3Q0vyY5Fn9X/h74LkXgOnHisSinD/lbczS/mh2LsvxvR38/NNSd19+LI3n5hABJkqQO4mlNSZKkDmI4kyRJ6iCGM0mSpA5iOJMkSeoghjNJkqQOYjiTpCMUEedExD+1ux2S5gfDmSRJUgcxnElaMCLipRHxzYjYEBEfiIjuiNgdEX8eEbdFxL9ExKqy7hkRcXP54OrPjD64OiJOjYgby4e6fysinlCufklEfCoifhARHxt9QoIkzZThTNKCEBE/CbwIODszzwCGgd+ieNrB+sx8EvBV4C3lIh8B3pCZT6UY6X20/GPAVVk81P3nKUZDBzgTeB1wOsVo52dXvEuS5qmedjdAkubIs4CfAm4pO7X6KR5QPsL4w5g/CvxjRCwHapn51bL8GuAfymf/DWTmZwAycx9Aub5vZvncwIjYAJwM3FT5XkmadwxnkhaKAK7JzMsPKoz4fyfUm+0z7fY3fB7G36+SZsnTmpIWin8BXhgRxwNExHER8TiK34MvLOu8BLgpM3cA2yPiGWX5y4CvZuYuYFNEXFiuozcijpnLnZA0//k/O0kLQmbeHhFvAr4YEV3AIPAa4FHgrHLeAxTXpQFcDLy/DF93A68oy18GfCAirijX8RtzuBuSFoDInG0PviQd/SJid2YuaXc7JGmUpzUlSZI6iD1nkiRJHcSeM0mSpA5iOJMkSeoghjNJkqQOYjiTJEnqIIYzSZKkDmI4kyRJ6iD/F3F4VSZDVOJKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(lst_loss, marker='s')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Word2Vec Skip-gram Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1606321030038,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "43pOYRh-MX_F",
    "outputId": "3de0675b-47af-462d-c927-f14a62933956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.390: sleep.\n",
      "cosine sim=0.374: players.\n",
      "cosine sim=0.348: consultants.\n",
      "cosine sim=0.342: ideological.\n"
     ]
    }
   ],
   "source": [
    "#計算字詞相似度\n",
    "\n",
    "def get_similarity(word, top_k, model, word2idx, idx2word):\n",
    "    W = (model.in_embedding.weight.data + model.out_embedding.weight.data) / 2\n",
    "    idx = word2idx.get(word, None)\n",
    "    \n",
    "    if not idx:\n",
    "        # 當出現不在字典中的字詞時，顯示Out of vocabulary error\n",
    "        raise ValueError(\"Out of vocabulary\")\n",
    "    else:\n",
    "        x = W[idx]\n",
    "        \n",
    "        # 使用cosine相似計算字詞間的相似程度\n",
    "        cos = torch.matmul(W, x) / (torch.sum(W * W, dim=-1) * torch.sum(x * x) + 1e-9).sqrt()\n",
    "        _, topk = torch.topk(cos, top_k+1)\n",
    "        \n",
    "        for i in topk[1:]:\n",
    "            print(f\"cosine sim={cos[int(i)]:.3f}: {idx2word[int(i)]}.\")\n",
    "\n",
    "get_similarity('love', 4, model, word2idx, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_tL9g0oMcCT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNRbZbSHSpiMTWmQCCagSqg",
   "collapsed_sections": [],
   "name": "word2vec高速化_作業解答.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
