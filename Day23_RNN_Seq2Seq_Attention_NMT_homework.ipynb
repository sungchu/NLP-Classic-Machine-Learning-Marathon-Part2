{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCIvz30AOj-H"
   },
   "source": [
    "# 作業 : 觀察機器翻譯 ATTENTION 內容 \n",
    "- 仔細地觀察機器翻譯 ATTENTION 結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usP1_X7qOv6F"
   },
   "source": [
    "# [作業目標]\n",
    "- 透過視覺化 注意力 attention 層 了解attention 的作用方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWGLeN9BOxEF"
   },
   "source": [
    "# [作業重點]\n",
    "- 透過視覺化 注意力 attention 層 了解attention 的作用方式\n",
    "- 原則上只要之前的訓練有跑完，這邊的程式可以執行成功最後只要觀察結果就好\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UIBD2Nn-OI-1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3057,
     "status": "ok",
     "timestamp": 1606747986284,
     "user": {
      "displayName": "Eddie Chen",
      "photoUrl": "",
      "userId": "03297804823735668650"
     },
     "user_tz": -480
    },
    "id": "FQoAR8K-RyHd",
    "outputId": "90f61737-da03-49ab-fc8d-a6d7041e6fe7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' 不是內部或外部命令、可執行的程式或批次檔。\n",
      "'export' 不是內部或外部命令、可執行的程式或批次檔。\n",
      "'mv' 不是內部或外部命令、可執行的程式或批次檔。\n"
     ]
    }
   ],
   "source": [
    "# Colab 進行matplotlib繪圖時顯示繁體中文\n",
    "# 下載字體並命名taipei_sans_tc_beta.ttf，移至指定路徑\n",
    "!wget -O taipei_sans_tc_beta.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
    "!mv taipei_sans_tc_beta.ttf /usr/local/lib/python3.6/dist-packages/matplotlib//mpl-data/fonts/ttf\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "import matplotlib.ticker as ticker\n",
    "# 自定義字體變數\n",
    "myfont = FontProperties(fname=r'/usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf/taipei_sans_tc_beta.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2587,
     "status": "ok",
     "timestamp": 1606747986286,
     "user": {
      "displayName": "Eddie Chen",
      "photoUrl": "",
      "userId": "03297804823735668650"
     },
     "user_tz": -480
    },
    "id": "BrbNQhl5R2MP",
    "outputId": "ce704d72-6df2-4a07-8afa-d0557b8c2073"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1138,
     "status": "ok",
     "timestamp": 1606747988513,
     "user": {
      "displayName": "Eddie Chen",
      "photoUrl": "",
      "userId": "03297804823735668650"
     },
     "user_tz": -480
    },
    "id": "wFjVGqegR5U8",
    "outputId": "90e653a6-c8b6-4305-f8c6-59e538678bc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:  ['He was drowned.', '他被淹死了。']\n",
      "Total records: 24360\n"
     ]
    }
   ],
   "source": [
    "data_dir = './cmn-eng/'\n",
    "lines = open(data_dir + 'cmn.txt' , encoding='utf-8').read().strip().split('\\n')\n",
    "trnslt_pairs = [[s for s in l.split('\\t')] for l in lines ]\n",
    "print (\"Sample: \" , trnslt_pairs[1000][0:2] )\n",
    "print (\"Total records:\" , len(trnslt_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2876,
     "status": "ok",
     "timestamp": 1606747990773,
     "user": {
      "displayName": "Eddie Chen",
      "photoUrl": "",
      "userId": "03297804823735668650"
     },
     "user_tz": -480
    },
    "id": "Tl-KIM-nSA-H",
    "outputId": "924da190-5818-4cad-8c4e-2a0069da256b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文語料的字元表長度:  2718 , 英文的字元表長度:  4103\n",
      "Sample SRC: ['他', '们', '没', '听'] TRG: ['they', 'did', \"n't\", 'listen', '.']\n"
     ]
    }
   ],
   "source": [
    "# 下載 spacy 的英文模型 幫我們做tokenize\n",
    "model_dir =  './'\n",
    "\n",
    "spacy_eng = spacy.load('en_core_web_sm')\n",
    "def tokenize_eng(text):\n",
    "    #清除不需要的字符\n",
    "    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "TRG = Field(tokenize = tokenize_eng, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_cmn(text):\n",
    "    #去掉非中文字元\n",
    "    regex = re.compile(r'[^\\u4e00-\\u9fa5A-Za-z0-9]')\n",
    "    text = regex.sub(' ', text)\n",
    "\n",
    "    return [word for word in text if word.strip()]\n",
    "    \n",
    "\n",
    "SRC = Field(tokenize = tokenize_cmn, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            include_lengths = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = TabularDataset.splits(\n",
    "    path = data_dir , format = 'csv', skip_header = True,\n",
    "    train='train.csv', validation='val.csv', test='test.csv',\n",
    "    fields=[\n",
    "        ('trg', TRG),\n",
    "        ('src', SRC)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 讀取之前儲存的 vocabulary\n",
    "SRC.vocab = torch.load(model_dir + 'SRC_vocab.pt')\n",
    "TRG.vocab = torch.load(model_dir + 'TRG_vocab.pt')\n",
    "\n",
    "print (\"中文語料的字元表長度: \" , len(SRC.vocab) , \", 英文的字元表長度: \" ,len(TRG.vocab))\n",
    "print (\"Sample SRC:\", test_dataset[0].src , \"TRG:\", test_dataset[0].trg)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_dataset, dev_dataset, test_dataset), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     sort_within_batch = True,\n",
    "     sort_key = lambda x : len(x.src),\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYoqlKcrq2Z_"
   },
   "source": [
    "# 模型主體 和前面範例程式一樣\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wj3ZTHDMSGOF"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden bz , dec_hid_dim\n",
    "        # encoder_outputs src len, bz , enc_hid_dim x 2\n",
    "        # mask bz , src len\n",
    "\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1) \n",
    "        # hidden unsqueeze bz , 1 , dec_hid_dim\n",
    "\n",
    "        attention = torch.matmul( hidden , encoder_outputs.permute(1, 2, 0)   )\n",
    "        # attention bz, 1 , src len\n",
    "\n",
    "        attention = attention.squeeze(1)\n",
    "        # squeeze bz , src len\n",
    "\n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TNzgZqHcS2CX"
   },
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        # 雙向 ＧＲＵ encoder \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_len):\n",
    "        \n",
    "        #src shape [src len, batch size]\n",
    "        #src_len shape [batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded shape [src len, batch size, emb dim]\n",
    "                \n",
    "        # 使用pack_padded_sequence 來壓縮序列        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
    "                \n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "\n",
    "        # 使用 pad_packed_sequence 用來展開序列成原本形狀的      \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
    "            \n",
    "            \n",
    "        #outputs shape [src len, batch size, hid dim * num directions]\n",
    "        #hidden shape [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden 堆疊 [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs 是最後一層 \n",
    "        \n",
    "        #hidden [-2, :, : ] 是最後一層 forwards RNN \n",
    "        #hidden [-1, :, : ] 是最後一層 backwards RNN\n",
    "        \n",
    "        # hidden 是最後再過一層 dense layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs shape [src len, batch size, enc hid dim * 2]\n",
    "        #hidden shape [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        # 單向 ＧＲＵ decoder \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        #input shape [batch size]\n",
    "        #hidden shape [batch size, dec hid dim]\n",
    "        #encoder_outputs shape [src len, batch size, enc hid dim * 2]\n",
    "        #mask shape [batch size, src len]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input shape [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded shape [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "                \n",
    "        #a shape [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a shape [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs shape [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted shape [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted shape [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input shape [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output shape [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden shape [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output shape [1, batch size, dec hid dim]\n",
    "        #hidden shape [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction shape [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)\n",
    "\n",
    "class Seq2SeqATTN(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "                    \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        mask = self.create_mask(src)\n",
    "\n",
    "        #mask = [batch size, src len]\n",
    "                \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
    "            #  and mask\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW2KIxhxrMGf"
   },
   "source": [
    "# 建立模型和重要參數 請保持和前面訓練時一樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1606748569939,
     "user": {
      "displayName": "Eddie Chen",
      "photoUrl": "",
      "userId": "03297804823735668650"
     },
     "user_tz": -480
    },
    "id": "ybIY0kKGS_gI",
    "outputId": "f3c7921e-ee12-4039-8dce-a72e64d7a4d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型全部參數量: 10,023,431 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqATTN(\n",
       "  (encoder): RNNEncoder(\n",
       "    (embedding): Embedding(2718, 256)\n",
       "    (rnn): GRU(256, 256, bidirectional=True)\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): RNNDecoder(\n",
       "    (attention): Attention()\n",
       "    (embedding): Embedding(4103, 256)\n",
       "    (rnn): GRU(768, 512)\n",
       "    (fc_out): Linear(in_features=1280, out_features=4103, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 256 # 注意 encoder hidden layer 設定 必須為 dec 的一半 \n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "LEARNING_RATE = 0.002\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = RNNEncoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = RNNDecoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "model = Seq2SeqATTN(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "\n",
    "def initial_mdl_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(initial_mdl_weights)\n",
    "print (\"模型全部參數量: {:10,d} \".format(sum(p.numel() for p in model.parameters())))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KOpjxQJmTDYU"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src, src_len = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, src_len.cpu(), trg, 0) #turn off teacher forcing\n",
    "            \n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1545,
     "status": "ok",
     "timestamp": 1606748577398,
     "user": {
      "displayName": "Eddie Chen",
      "photoUrl": "",
      "userId": "03297804823735668650"
     },
     "user_tz": -480
    },
    "id": "Ukg9t_iOTHlG",
    "outputId": "b2c6b18c-5243-4b66-fd4f-8ab83d321c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.561 | Test PPL:  35.205 |\n"
     ]
    }
   ],
   "source": [
    "model_dir =  './'\n",
    "model.load_state_dict(torch.load(model_dir + 'best-model.pt'))\n",
    "#model.load_state_dict(torch.load(model_dir + 'model-7.pt'))\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q-caE1Y1TL5p"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    #if isinstance(sentence, str):\n",
    "    #    nlp = spacy_en = spacy.load('en_core_web_sm')\n",
    "    #    tokens = [token.text.lower() for token in spacy_en(sentence)]\n",
    "    #else:\n",
    "    #    tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [token.lower() for token in sentence]\n",
    "        \n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor, src_len.cpu())\n",
    "\n",
    "    mask = model.create_mask(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "\n",
    "        attentions[i] = attention\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9jhh_5_SYYLT"
   },
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    #fontdict = {\"fontproperties\": zhfont}\n",
    "    \n",
    "    #ax.set_xticks(range(max(max_len_tar, len(predicted_seq))))\n",
    "    #ax.set_xlim(-0.5, max_len_tar -1.5)\n",
    "    \n",
    "    #ax.set_yticks(range(len(sentence) + 2))\n",
    "    #ax.set_xticklabels([subword_encoder_zh.decode([i]) for i in predicted_seq \n",
    "    #                    if i < subword_encoder_zh.vocab_size], \n",
    "    #                   fontdict=fontdict, fontsize=18)\n",
    "    \n",
    "    #plt.rcParams[\"font.family\"]=\"sans-serif\"\n",
    "    #plt.rcParams['font.sans-serif']=['STSong'] #用来正常显示中文标签\n",
    "    \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                       rotation=45 , fontproperties=myfont) #, fontdict=fontdict)\n",
    "    ax.set_yticklabels(['']+translation, fontproperties=myfont) # , fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4n7915Mrcs1"
   },
   "source": [
    "# 作業重點\n",
    "## 請選擇一個好的翻譯結果\n",
    "## 將其 ATTENTION 視覺化 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 953,
     "status": "ok",
     "timestamp": 1606748631874,
     "user": {
      "displayName": "Eddie Chen",
      "photoUrl": "",
      "userId": "03297804823735668650"
     },
     "user_tz": -480
    },
    "id": "pRYXjqgvYb-E",
    "outputId": "3532080c-035a-48f1-c89d-107740135895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['她', '沒', '有', '在', '星', '期', '天', '來', '找', '我', '而', '是', '星', '期', '一']\n",
      "trg = ['she', 'did', 'not', 'visit', 'me', 'on', 'sunday', 'but', 'on', 'monday', '.']\n",
      "predicted trg = ['she', 'did', \"n't\", 'finished', 'me', 'to', 'me', 'to', 'me', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# 請在這邊自行調整 sample index \n",
    "# 觀察不同句子的 ATTENTION 結果\n",
    "example_idx =499\n",
    "\n",
    "src = vars(train_dataset.examples[example_idx])['src']\n",
    "trg = vars(train_dataset.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n",
    "\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cdlptGJrsfv"
   },
   "source": [
    "# 請觀察翻譯文 和被翻譯文的語意對應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1606748001188,
     "user": {
      "displayName": "Eddie Chen",
      "photoUrl": "",
      "userId": "03297804823735668650"
     },
     "user_tz": -480
    },
    "id": "H8f8csPSYfkU",
    "outputId": "61910059-d71a-4960-fa1a-b83db6cb6a39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "她沒有在星期天來找我而是星期一\n"
     ]
    }
   ],
   "source": [
    "print (\"\".join(src ))\n",
    "# display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ake_IJd2YiG3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
