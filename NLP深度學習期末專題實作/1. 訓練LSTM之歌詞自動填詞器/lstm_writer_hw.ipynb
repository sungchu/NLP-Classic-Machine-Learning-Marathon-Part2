{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSmJJczZo5zp"
   },
   "source": [
    "# 專題（一）：訓練LSTM之歌詞自動填詞器\n",
    "\n",
    "## 專案目標\n",
    "- 目標：使用 LSTM 模型去學習五月天歌詞，並且可以自動填詞來產生歌詞\n",
    "- mayday_lyrics.txt 資料說明：\n",
    "    - 每一行都是一首歌的歌詞\n",
    "    - 除去標點符號並以空白表示間格\n",
    "- 利用 mayday_lyrics.txt 來產生歌詞的序列\n",
    "- 使用 LSTM 模型去學習歌詞的序列\n",
    "- 當我們給定開頭的一段歌詞，例如：”給我一首歌”，就可以用 LSTM 猜下一個字，反覆這個過程就可以自動填詞\n",
    "\n",
    "## 實作提示\n",
    "- STEP1：從 mayday_lyrics.txt 中取出歌詞\n",
    "- STEP2：建立每個字的 Index\n",
    "- STEP3：用 Rolling 的方式打造 LyricsDataset\n",
    "- STEP4：使用 DataLoader 來包裝 LyricsDataset\n",
    "- STEP5：建立 LSTM 模型： inputs > nn.Embedding > nn.LSTM > nn.Dropout > 取最後一個 state > nn.Linear > softmax\n",
    "- STEP6：開始訓練並調整參數\n",
    "- STEP7：進行 Demo，給定 pre_text ，使用模型迭代的預測下一個字產生歌詞\n",
    "- (進階) STEP8：在 Demo 時可以採用依照 Softmax 機率來作隨機採樣，這可以增加隨機性，讓歌詞有更多變化，當然你還可以使用機率閥值來避免太奇怪的字出現\n",
    "\n",
    "## 重要知識點：專題結束後你可以學會\n",
    "- 如何讀取並處理需要 Rolling 的序列資料\n",
    "- 了解如何用 Pytorch 建制一個 LSTM 的模型\n",
    "- 學會如何訓練一個語言模型\n",
    "- 學會如何隨機抽樣自 Softmax 的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hen1MQ1F_cly"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7joX8NEEu90J"
   },
   "outputs": [],
   "source": [
    "# from: https://github.com/gaussic/Chinese-Lyric-Corpus\n",
    "\n",
    "lyrics_list = [line.strip() for line in open('mayday_lyrics.txt',encoding=\"utf-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_P3Bonv_7FpS"
   },
   "outputs": [],
   "source": [
    "# 建立詞典對照表\n",
    "word2index = {}\n",
    "index2word = {}\n",
    "\n",
    "i = 0\n",
    "for words in lyrics_list:\n",
    "    for word in words:\n",
    "        if word not in word2index:\n",
    "            word2index[word] = i\n",
    "            index2word[i] = word\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nueOEx287Hpm",
    "outputId": "c6660bfe-a513-424d-95bd-a8b8400255d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2101"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['摸不到的顏色 是否叫',\n",
       " '不到的顏色 是否叫彩',\n",
       " '到的顏色 是否叫彩虹',\n",
       " '的顏色 是否叫彩虹 ',\n",
       " '顏色 是否叫彩虹 看',\n",
       " '色 是否叫彩虹 看不',\n",
       " ' 是否叫彩虹 看不到',\n",
       " '是否叫彩虹 看不到的',\n",
       " '否叫彩虹 看不到的擁',\n",
       " '叫彩虹 看不到的擁抱',\n",
       " '彩虹 看不到的擁抱 ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unrollings = 10\n",
    "samples = []\n",
    "for i in lyrics_list:\n",
    "    for j in range(len(i) - num_unrollings + 1):\n",
    "        samples.append(i[j:j+num_unrollings])\n",
    "samples[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BwIpjwU_8YJB"
   },
   "outputs": [],
   "source": [
    "# 建立數據集\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics_list, word2index, num_unrollings=10):\n",
    "        ## Code Here\n",
    "        self.word2index = word2index\n",
    "        self.samples = []\n",
    "        for i in lyrics_list:\n",
    "            for j in range(len(i) - num_unrollings + 1):\n",
    "                self.samples.append(i[j:j+num_unrollings])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ## Code Here\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        input_lyric = [self.word2index[w] for w in sample[:-1]]\n",
    "        input_lyric = torch.tensor(input_lyric, dtype=torch.long)\n",
    "        output_lyric = self.word2index[sample[-1]]\n",
    "        output_lyric = torch.tensor(output_lyric, dtype=torch.long)\n",
    "        \n",
    "        return input_lyric, output_lyric\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_L7UokS6_W7O"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataset = LyricsDataset(lyrics_list, word2index)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_HV3bcPM_l7X"
   },
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "class LM_LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden, vocab_size, num_layers, dropout_ratio):\n",
    "        super(LM_LSTM, self).__init__()\n",
    "        ## Code Here\n",
    "        self.n_hidden = n_hidden\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        self.embed = torch.nn.Embedding(vocab_size, n_hidden)\n",
    "        self.lstm = nn.LSTM(input_size = n_hidden, \n",
    "                            hidden_size = n_hidden,\n",
    "                            num_layers = num_layers,\n",
    "                            dropout = dropout_ratio)\n",
    "        self.fc = nn.Linear(in_features=n_hidden, out_features=vocab_size)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## Code Here\n",
    "        embed = self.embed(inputs) # [128, 9, 128]\n",
    "        embed = embed.transpose(0, 1) # [9, 128, 128]\n",
    "        \n",
    "        outputs, _ = self.lstm(embed)\n",
    "        outputs = self.dropout(outputs)\n",
    "        output = outputs[-1]  # [batch_size, n_hidden]\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-tNgfswV_nc1"
   },
   "outputs": [],
   "source": [
    "def train_batch(model, data, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    inputs, targets = [d.to(device) for d in data]\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_QVIJqHRsnX",
    "outputId": "3ad0be24-37a2-463c-90db-206ca71f8251"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\ntuhuser\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 train_loss:  5.65644539985612\n",
      "epoch  2 train_loss:  5.263513305908318\n",
      "epoch  3 train_loss:  4.994525241053509\n",
      "epoch  4 train_loss:  4.753529821982881\n",
      "epoch  5 train_loss:  4.539069605684454\n",
      "epoch  6 train_loss:  4.333671154475996\n",
      "epoch  7 train_loss:  4.155282433800497\n",
      "epoch  8 train_loss:  3.991806651645844\n",
      "epoch  9 train_loss:  3.8339239407837304\n",
      "epoch  10 train_loss:  3.6884352194692727\n",
      "Example: \"摸不到的顏色 是否\"+\"要\"\n",
      "Example: \" 只留下結果 時間\"+\"人\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  11 train_loss:  3.555434479628527\n",
      "epoch  12 train_loss:  3.422983957487341\n",
      "epoch  13 train_loss:  3.3094714500068996\n",
      "epoch  14 train_loss:  3.2054917369992055\n",
      "epoch  15 train_loss:  3.099463789831735\n",
      "epoch  16 train_loss:  2.997106836811381\n",
      "epoch  17 train_loss:  2.9067579838417243\n",
      "epoch  18 train_loss:  2.8193396126867944\n",
      "epoch  19 train_loss:  2.73430210017063\n",
      "epoch  20 train_loss:  2.660477321575358\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"變\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  21 train_loss:  2.591429374886416\n",
      "epoch  22 train_loss:  2.516083451641324\n",
      "epoch  23 train_loss:  2.450143078286256\n",
      "epoch  24 train_loss:  2.3969765899253153\n",
      "epoch  25 train_loss:  2.3291867333677776\n",
      "epoch  26 train_loss:  2.274226489462977\n",
      "epoch  27 train_loss:  2.229487610303262\n",
      "epoch  28 train_loss:  2.175041979012485\n",
      "epoch  29 train_loss:  2.1253171352001625\n",
      "epoch  30 train_loss:  2.0812566048000307\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"年\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  31 train_loss:  2.0424863534553417\n",
      "epoch  32 train_loss:  1.991547648380856\n",
      "epoch  33 train_loss:  1.959209074888314\n",
      "epoch  34 train_loss:  1.9217338525513339\n",
      "epoch  35 train_loss:  1.879586091943275\n",
      "epoch  36 train_loss:  1.8471602257271813\n",
      "epoch  37 train_loss:  1.8191411391505012\n",
      "epoch  38 train_loss:  1.787009857319328\n",
      "epoch  39 train_loss:  1.7514550285192028\n",
      "epoch  40 train_loss:  1.7200664455733203\n",
      "Example: \"摸不到的顏色 是否\"+\"緊\"\n",
      "Example: \" 只留下結果 時間\"+\"偷\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  41 train_loss:  1.697510086810737\n",
      "epoch  42 train_loss:  1.6726953754358718\n",
      "epoch  43 train_loss:  1.642920024217122\n",
      "epoch  44 train_loss:  1.6127902364525843\n",
      "epoch  45 train_loss:  1.5916730806473935\n",
      "epoch  46 train_loss:  1.5653540654081854\n",
      "epoch  47 train_loss:  1.5531098271271222\n",
      "epoch  48 train_loss:  1.5277872486386823\n",
      "epoch  49 train_loss:  1.5039722747013435\n",
      "epoch  50 train_loss:  1.487957329817808\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"都\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"此\"\n",
      "epoch  51 train_loss:  1.4564068083632045\n",
      "epoch  52 train_loss:  1.4490095168415145\n",
      "epoch  53 train_loss:  1.4383830825678736\n",
      "epoch  54 train_loss:  1.4087991733810015\n",
      "epoch  55 train_loss:  1.3983547337337736\n",
      "epoch  56 train_loss:  1.37838180230606\n",
      "epoch  57 train_loss:  1.3593213505699353\n",
      "epoch  58 train_loss:  1.3387621240322691\n",
      "epoch  59 train_loss:  1.327158910993232\n",
      "epoch  60 train_loss:  1.3250309708729953\n",
      "Example: \"摸不到的顏色 是否\"+\"看\"\n",
      "Example: \" 只留下結果 時間\"+\"終\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  61 train_loss:  1.3023390474554948\n",
      "epoch  62 train_loss:  1.293479519634681\n",
      "epoch  63 train_loss:  1.2779958560916205\n",
      "epoch  64 train_loss:  1.2670659282120285\n",
      "epoch  65 train_loss:  1.245795345243066\n",
      "epoch  66 train_loss:  1.2345634468148876\n",
      "epoch  67 train_loss:  1.2190794501366207\n",
      "epoch  68 train_loss:  1.2088624180991303\n",
      "epoch  69 train_loss:  1.1995898996348515\n",
      "epoch  70 train_loss:  1.1863232455066859\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"多\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"痛\"\n",
      "epoch  71 train_loss:  1.1755110440158298\n",
      "epoch  72 train_loss:  1.173229134416321\n",
      "epoch  73 train_loss:  1.1558664700315944\n",
      "epoch  74 train_loss:  1.1438930053094964\n",
      "epoch  75 train_loss:  1.1332374905355802\n",
      "epoch  76 train_loss:  1.1267393830584047\n",
      "epoch  77 train_loss:  1.1181913911197385\n",
      "epoch  78 train_loss:  1.113665126303026\n",
      "epoch  79 train_loss:  1.0922422096196511\n",
      "epoch  80 train_loss:  1.0915115130722004\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"年\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  81 train_loss:  1.0832734815356444\n",
      "epoch  82 train_loss:  1.0753302614072608\n",
      "epoch  83 train_loss:  1.065338840900934\n",
      "epoch  84 train_loss:  1.0549169569353989\n",
      "epoch  85 train_loss:  1.0432418619384574\n",
      "epoch  86 train_loss:  1.041478275521529\n",
      "epoch  87 train_loss:  1.0368349590861154\n",
      "epoch  88 train_loss:  1.0280474982941543\n",
      "epoch  89 train_loss:  1.0154315141422168\n",
      "epoch  90 train_loss:  1.0124389762499102\n",
      "Example: \"摸不到的顏色 是否\"+\"嘆\"\n",
      "Example: \" 只留下結果 時間\"+\"偷\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"血\"\n",
      "epoch  91 train_loss:  1.0029758042437389\n",
      "epoch  92 train_loss:  0.9976664444022925\n",
      "epoch  93 train_loss:  0.993799819834294\n",
      "epoch  94 train_loss:  0.9852459536981527\n",
      "epoch  95 train_loss:  0.9856605721443312\n",
      "epoch  96 train_loss:  0.9721425115888214\n",
      "epoch  97 train_loss:  0.9654938938245932\n",
      "epoch  98 train_loss:  0.9560598585245346\n",
      "epoch  99 train_loss:  0.9544796770255585\n",
      "epoch  100 train_loss:  0.945830271740402\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"來\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LM_LSTM(128, len(word2index), 2, 0.3)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(1, 1 + epochs):\n",
    "    tot_train_loss = 0\n",
    "    tot_train_count = 0\n",
    "\n",
    "    for train_data in train_loader:\n",
    "        loss = train_batch(model, train_data, criterion, optimizer, device)\n",
    "\n",
    "        tot_train_loss += loss\n",
    "        tot_train_count += train_data[0].size(0)\n",
    "\n",
    "    print('epoch ', epoch, 'train_loss: ', tot_train_loss / tot_train_count)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        for idx in [0, 50, 99]:\n",
    "            input_batch = dataset[idx][0].unsqueeze(0).to(device)\n",
    "            predict = model(input_batch).argmax(dim=-1).item()\n",
    "            print('Example: \"{}\"+\"{}\"'.format(dataset.samples[idx][:-1], index2word[predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anMER7TJTWKy",
    "outputId": "8ad0434c-91ee-4542-cc3a-bf881d2fb379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "給我一首歌子 已經不能原諒我相過 時間變成那們館的 孩復就算的結局 誰能看見 你是不去 太大的人 每天的平圍 \n"
     ]
    }
   ],
   "source": [
    "# 模型inference\n",
    "pre_text = '給我一首歌'\n",
    "generate_len = 50\n",
    "prob_threshold = 0.01\n",
    "\n",
    "result = [word2index[c] for c in pre_text]\n",
    "for _ in range(generate_len):\n",
    "    input_example = torch.tensor([result], dtype=torch.long, device=device)\n",
    "    logit = model(input_example)\n",
    "\n",
    "    ## Code Here\n",
    "    prob = F.softmax(logit, dim=-1)\n",
    "    probs = torch.where(prob > prob_threshold, prob, torch.zeros_like(prob))\n",
    "    predict = torch.multinomial(probs, 1).item()\n",
    "    ## End\n",
    "    result += [predict]\n",
    "print(''.join([index2word[i] for i in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeJ2a5VM8OPM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_writer_hw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
