{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>主題:\n",
    "啤酒評論評分預測 - 分詞器(Tokenizer)\n",
    "### <strong>說明:\n",
    "繼續上次啤酒的評鑑資料集的練習，還記得在上次的資料初步分析之後，我們對於BERT模型最大 <br />\n",
    "長度的限制是255嗎? 然而這還只是未使用分詞器所得到的結論，當真正使用分詞器之後，每個 <br />\n",
    "評論具的token數可能會與我們先前的評估有所不同，因此這是作業主要是以BERT分瓷器來驗證 <br />\n",
    "上次作業得到的結論是否需要修正。\n",
    "### <strong>題目\n",
    "1. 創建英文BERT所使用的分詞器，提供下一題分析以及後續訓練使用\n",
    "2. 以分詞器生成每個評論語句的token，並評估上次得到的最大長度限制是否合理\n",
    "\n",
    "#### <strong>提示: 不要忘記加上[SEP]與[CLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.read_json(\"./data/train_set.json\")\n",
    "TEST = pd.read_json(\"./data/test_set.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
