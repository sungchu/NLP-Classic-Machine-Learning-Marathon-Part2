{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import clip_grads, convert_one_hot, preprocess, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 7, 3, 0, 1, 6]),\n",
       " array([[4, 7],\n",
       "        [5, 3],\n",
       "        [7, 0],\n",
       "        [3, 1],\n",
       "        [0, 6],\n",
       "        [1, 2]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "\n",
    "    targets = []\n",
    "    contexts = corpus[window_size:-window_size]\n",
    "\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                # skip target word itself\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        targets.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "contexts, targets= create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0]]),\n",
       " array([[[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0]],\n",
       " \n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "contexts = convert_one_hot(contexts, len(word2idx))\n",
    "targets = convert_one_hot(targets, len(word2idx))\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H)\n",
    "        W_out = 0.01 * np.random.randn(H, V)\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in)\n",
    "        self.out_layer = Dense(W_out)\n",
    "        self.loss_layers = [SoftmaxWithCrossEntropy() for i in range(window_size * 2)]\n",
    "        \n",
    "\n",
    "        layers = [self.in_layer, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts)\n",
    "        s = self.out_layer.forward(h)\n",
    "        \n",
    "        loss = sum([self.loss_layers[i].forward(s, targets[:, i]) for i in range(self.window_size * 2)])\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        ds = sum([self.loss_layers[i].backward(dout) for i in range(self.window_size * 2)])\n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 196/1000 [00:00<00:00, 1945.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.158743611438252\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.158993410802887\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.158735697261758\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.1587627344531315\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.158641617771647\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.158575679516678\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158732933366427\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.158418778733304\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.158603833098859\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.15835095671944\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158068379039738\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.158403407533301\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.158058629889173\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.158243498816002\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.157962667715751\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.157596721966199\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.158162951514391\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.1571672967055635\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.1575891676958445\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.157609763420821\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.157262646002874\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.156632952910579\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.1572163783589815\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.155876141310872\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.156881739563245\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.155552002390811\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.156018056741004\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.155545152782347\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.154958446876356\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.1546696897018816\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.153833244497346\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.154124156085958\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.152381456900535\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.151638360352557\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.151541728537804\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.152038840563533\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.150002144785438\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.1475226297468275\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.1460559559140835\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.149525265754007\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.14156659869723\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.14171367103551\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.145231380481005\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.139275405417099\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.138118069952638\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.131556371527135\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.137778264499057\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.129658414765927\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.127402841924643\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.117757642993476\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.130723362454704\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.0969396080368305\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.1056008195502525\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.104077498894567\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.109719713946674\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.094069179282949\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.089081723060649\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.052786181221588\n",
      "Epoch: 59, Iteration: 1/2, Loss: 4.0714434639910655\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.059776071166331\n",
      "Epoch: 61, Iteration: 1/2, Loss: 4.025656687490268\n",
      "Epoch: 62, Iteration: 1/2, Loss: 4.035999221696291\n",
      "Epoch: 63, Iteration: 1/2, Loss: 4.020697432507124\n",
      "Epoch: 64, Iteration: 1/2, Loss: 3.9778024528429494\n",
      "Epoch: 65, Iteration: 1/2, Loss: 4.001345992433037\n",
      "Epoch: 66, Iteration: 1/2, Loss: 3.9343546124258304\n",
      "Epoch: 67, Iteration: 1/2, Loss: 3.897163174406547\n",
      "Epoch: 68, Iteration: 1/2, Loss: 3.9123467248155253\n",
      "Epoch: 69, Iteration: 1/2, Loss: 3.943363726619789\n",
      "Epoch: 70, Iteration: 1/2, Loss: 3.8419871825482765\n",
      "Epoch: 71, Iteration: 1/2, Loss: 3.8895596400009587\n",
      "Epoch: 72, Iteration: 1/2, Loss: 3.7466889675192077\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.8338889792236714\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.771460717058168\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.605670223647162\n",
      "Epoch: 76, Iteration: 1/2, Loss: 3.5856522054218187\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.7285826463153695\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.553947872735665\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.550503732742219\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.5595725158629326\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.4035724523324635\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.457156540960039\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.286557056118133\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.1004504593600353\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.4053349197194165\n",
      "Epoch: 86, Iteration: 1/2, Loss: 3.19517340173106\n",
      "Epoch: 87, Iteration: 1/2, Loss: 3.0357436631704724\n",
      "Epoch: 88, Iteration: 1/2, Loss: 3.0303855290063533\n",
      "Epoch: 89, Iteration: 1/2, Loss: 3.2217936671774554\n",
      "Epoch: 90, Iteration: 1/2, Loss: 3.191971628395839\n",
      "Epoch: 91, Iteration: 1/2, Loss: 2.888003175912169\n",
      "Epoch: 92, Iteration: 1/2, Loss: 2.976402475796649\n",
      "Epoch: 93, Iteration: 1/2, Loss: 2.7746577388351263\n",
      "Epoch: 94, Iteration: 1/2, Loss: 2.921803164955197\n",
      "Epoch: 95, Iteration: 1/2, Loss: 2.7756762525674032\n",
      "Epoch: 96, Iteration: 1/2, Loss: 2.770775899177046\n",
      "Epoch: 97, Iteration: 1/2, Loss: 2.62001731505028\n",
      "Epoch: 98, Iteration: 1/2, Loss: 2.7685717185371352\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.810422045207454\n",
      "Epoch: 100, Iteration: 1/2, Loss: 2.5331663599407097\n",
      "Epoch: 101, Iteration: 1/2, Loss: 2.4055220596880975\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.632511879208537\n",
      "Epoch: 103, Iteration: 1/2, Loss: 2.5150865497579664\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.5710144047790076\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.3675659928575126\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.3736124062618957\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.415958344117099\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.4155348824582146\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.205583879279622\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.387823252223207\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.2997188559411565\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.1121958666544858\n",
      "Epoch: 113, Iteration: 1/2, Loss: 2.1520482412313933\n",
      "Epoch: 114, Iteration: 1/2, Loss: 2.199233525398332\n",
      "Epoch: 115, Iteration: 1/2, Loss: 2.1392491783503846\n",
      "Epoch: 116, Iteration: 1/2, Loss: 2.1707369332929685\n",
      "Epoch: 117, Iteration: 1/2, Loss: 1.9840108571596624\n",
      "Epoch: 118, Iteration: 1/2, Loss: 2.117622897349983\n",
      "Epoch: 119, Iteration: 1/2, Loss: 1.9940173442917573\n",
      "Epoch: 120, Iteration: 1/2, Loss: 1.9834162277647496\n",
      "Epoch: 121, Iteration: 1/2, Loss: 2.0558193874385955\n",
      "Epoch: 122, Iteration: 1/2, Loss: 1.935291047006836\n",
      "Epoch: 123, Iteration: 1/2, Loss: 1.9639142078106486\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.927158262222978\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.9338136923156024\n",
      "Epoch: 126, Iteration: 1/2, Loss: 1.9074241710757027\n",
      "Epoch: 127, Iteration: 1/2, Loss: 1.836121786049009\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.8964244175419451\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.8372146583529634\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.8194227343834632\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.7696130416686346\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.8108460494556704\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.798648221367066\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.7561593008726413\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.772876973376864\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.745869471420771\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.7189781900180638\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.7120253019948284\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.7288309215946516\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.6475454300061956\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.7052623730721153\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.6990747446581018\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.670629179702802\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.662931940067774\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.62873695061607\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.667328156683589\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.634548447042619\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.6165881996045928\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.6375432274122421\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.627369636564239\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.5877342675593566\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.5958167214738461\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.6082531286386579\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.6141793991550806\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.5884668810296185\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.5618622837888552\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.578907540612459\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.5715925269513753\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.580894855368531\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.571347361036655\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.5465028742227183\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.5662816284311945\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.5491879919561413\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.5370890610566517\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.5438497307255297\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.556734539434367\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5240948666811118\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.526661073191884\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.5417636098295509\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.5132166852296354\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.53998898172051\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.5169602482893205\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.5020565058740099\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.5383640783802983\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.4951531090723362\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.5074124304655296\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.5216106737387023\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.5019322360735456\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.4983964476285019\n",
      "Epoch: 180, Iteration: 1/2, Loss: 1.5016918858577801\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.5082521997843803\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.490904885774234\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.509416524790673\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.485279313793122\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.4959428835824282\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.481192062839566\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.4960580111745883\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.4857589431193616\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.4868011486718729\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.4755799016201105\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.478161716693566\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.4795624504610094\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.4787064240560044\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.4826320832654494\n",
      "Epoch: 195, Iteration: 1/2, Loss: 1.4709927648571024\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.473676686773957\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4635348510839528\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.479604749874479\n",
      "Epoch: 199, Iteration: 1/2, Loss: 1.4695743693097576\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.4684446592993554\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.466150305906593\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.4665284212210494\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.462732442697133\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.4645091139281678\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.4582213743077688\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.4653159983384934\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.455445378801525\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4610090233668767\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.4641707114735198\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.4620751138796266\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.456488072691117\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.4540750694661375\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.4504643407240518\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.454614172989654\n",
      "Epoch: 215, Iteration: 1/2, Loss: 1.4528695515889039\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.4526094131748466\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.4504344909939588\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.4504477664504964\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.4539927677432574\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.4450431227979426\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.447319566667682\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.442999281839509\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.4466098171039272\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.4537025421883019\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.4380615153069898\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.4491536732293941\n",
      "Epoch: 227, Iteration: 1/2, Loss: 1.4464336738558847\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.4348226976264258\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.444777893280782\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.4418159452539425\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.4390130171614868\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.4437395495324856\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.4452293501544204\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.4334339654554573\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.4358538033182437\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.4428483110215475\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.436726784835297\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.442097224861446\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.4330638086711733\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.4338926225331838\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.4354505599696408\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4324552773528234\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.4400302022369191\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4324638606455815\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.433884598508999\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.4353105478033548\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.4271672967096614\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.4367104570164164\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.4280634532265148\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.4337427524796043\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.4284772397895393\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.4289677458836936\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.4331618531493606\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.4280149546731802\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.4341676828067493\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.4272105836004867\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.423618139589483\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.4342604393148988\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.4261019849850616\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.4287159972622812\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.4243671247177523\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.4297408403266387\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.4247218585668624\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.422005524478501\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.4300697367598298\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.424302671892982\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.4218730086832403\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.4267600891375594\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.4204694079966766\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.4249931834835126\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.4229631773652525\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.4253822894750072\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.4220397149472372\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.4252812559712833\n",
      "Epoch: 275, Iteration: 1/2, Loss: 1.4217017269916645\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.4206480236852677\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.4223034700900197\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.4192489154203343\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.4226952315144734\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.419288291268001\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.4226537120039189\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.4182130099729926\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.420771384659676\n",
      "Epoch: 284, Iteration: 1/2, Loss: 1.4210642466935832\n",
      "Epoch: 285, Iteration: 1/2, Loss: 1.419494795972975\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.4187359370051986\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4197816154231944\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.4179883533891298\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4170148864472392\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4194810576905843\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.4168282303457524\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.4185606671443778\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.4171089799907541\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.4182130859667463\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.4188628612715113\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.4158319492327016\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.4145069501783858\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.4157219654124682\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.4180086670173262\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.4159497996289638\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.415882824663907\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.416265071574187\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4157655834166485\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.4127529303618864\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.4187039178158947\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.4135006687474463\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.413178275191051\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.4148068841669845\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.4164690769878208\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.4113944241096892\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.4167966565302292\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.4109733714945731\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.4142762323286335\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.4117142827112001\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.4131416907343435\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4159926105704743\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.4097533369010198\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.4152680694128383\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.4113374546773767\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.4129801625537681\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4112468083481156\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4098750036352743\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.413977119221945\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.4121520268927292\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.4111029751626836\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.4124506198416746\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.4089807784211037\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.411976039767446\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.410187704577541\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.41246445684563\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.4068154729886169\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.4137520348072936\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.4086388202197244\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.4093520435706717\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.411881251370144\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.406977431419402\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.4113994064050508\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.4100047794326505\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.4091350908572373\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4093789555840621\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.4094897530221968\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.4098637636928988\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4071144425780453\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4083159930729376\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.410082218307466\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4070505688526753\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.409706458785588\n",
      "Epoch: 348, Iteration: 1/2, Loss: 1.4093988477989643\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.4053746573843844\n",
      "Epoch: 350, Iteration: 1/2, Loss: 1.4096933375864487\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4078730759784865\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.4087880600368492\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.4046127359209009\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.408991283899053\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4072567091604689\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.4079670137279092\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.4069316240630059\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.4076502340720127\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.4052935586102482\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.4079025142058943\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.4063559287433105\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.4070406778234674\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.4077384862842606\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.4050250316641173\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.4079176428320186\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.4041202310090153\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.4081685631199345\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.4044105866384995\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4069081743939278\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.4051797539955264\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4052272416027343\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.4042700968426478\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.406834558306406\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.4054066032048862\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.4067013586867672\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.4031151209615902\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.4072061418503985\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.4034938679439568\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.4037966071106958\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.4054348046129195\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4064608509377334\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.4035014640946706\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.403252389396109\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.4055991066165445\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.4051486568336182\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4032196214733998\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.4056601673386988\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.4026945298927291\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.4047418113566963\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.4039666453005588\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.403547417954612\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.4040097130805416\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.4042398443339468\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.4020308913437005\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.4035611766196143\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.4046710689439772\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.4033961619534099\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.4026669423669504\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.403960080605044\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.4038044265412835\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.4022574608965457\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.4028119304631992\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.4034204165032587\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.401530986658126\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.4046285824598188\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.4016897722861825\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.4029578777971314\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.401753515829093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 632/1000 [00:00<00:00, 2031.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 409, Iteration: 1/2, Loss: 1.402984401026453\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.4031202591672745\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.402028683306611\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.4023857706981722\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.4033776178717834\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.4001911316207907\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.401414617684261\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.4029511907279357\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.401960066911045\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.4032957016760506\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.4000598259016417\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.4017356057002208\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.4024233333075058\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.4003782468420694\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.401543367708948\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.4028707067313637\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.4010724324752815\n",
      "Epoch: 426, Iteration: 1/2, Loss: 1.4006082027579814\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.4008276088043434\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.4024229618569413\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.400853812798905\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.4011004233468518\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.401952134803489\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.3991976498288605\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.4022460708750888\n",
      "Epoch: 434, Iteration: 1/2, Loss: 1.4017772498891137\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.3997304709641887\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.4014992469411114\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.4002810643147279\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.4008810172415593\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.3992584637178656\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.4017921322575235\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.40003491160157\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.400584202430761\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.3998833692947148\n",
      "Epoch: 444, Iteration: 1/2, Loss: 1.4003908132776002\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.4008270357115937\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.3989054137674808\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.401518725278354\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.3986828949927845\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.4012458065023254\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.3999635693823862\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.4004928895008957\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.3992709571886244\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.3993019334008228\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.3990517084980687\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.4013403219759684\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.3989485906705812\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.3986700449017866\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.4008814063603234\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.3988145469322295\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.3997284642586587\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.3996812177632372\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.3994629167863244\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.3981182270184382\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.3991410136926818\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.3996064277960576\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.3995108086364998\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.3984784436410225\n",
      "Epoch: 468, Iteration: 1/2, Loss: 1.399567942271974\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.3995332226055692\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.3983766342386819\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.398913563077429\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.398506135064844\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.3987010190836235\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.4003092618859503\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.3978250157728054\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.3988339117264845\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.3984258921714037\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.3989560316766023\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.398229415465227\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.398918197399245\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.3980737729334953\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.3991458782053567\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.3986651751720063\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3977116759481611\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.398368982097666\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.397385426043591\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3990449175235737\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.3978600359628295\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.39909113497388\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.396763191735904\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.3987712569328683\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.3976923069721163\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.3980648247715943\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.3984448287282196\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.3973247951361603\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.397977185425622\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.3968622053513857\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.3989401349171509\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3977436807289647\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.3975927754668112\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3978446460721146\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.3970734685449944\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.3987934886955555\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3966142584351284\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.3971085002477595\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.3981897104218954\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.396623655870615\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.3984982490496476\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.3966252669259394\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.397962172139135\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.3960891212007485\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.3981513838372557\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.3966756777136364\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.3978480278993959\n",
      "Epoch: 515, Iteration: 1/2, Loss: 1.3964245060063074\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.3976357908286157\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.3970883108243268\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.3970901053818316\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3975225911737663\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.3965501116536971\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.3964234995431872\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.3969183089068857\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3972412497823163\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.3969159797300108\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.39769241279172\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.3959090710331603\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.3976209610817063\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.395117664532678\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.397174926142661\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.3968320038076394\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.3965153785852555\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.3960374560772322\n",
      "Epoch: 533, Iteration: 1/2, Loss: 1.3977252990429978\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3961789572222545\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3963351762507152\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.396158380353092\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.3975500658294084\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.395490218853385\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.3963708704454505\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.3961405487148282\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.3969474468589023\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.3956482178355736\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3968833136526637\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.3958909709569662\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.3961918679655434\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.3962214367981756\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3963985518165796\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.396029687347644\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.3958191308402126\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.3960456781377513\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.3956237065669668\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.3965399819736635\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.395089322385961\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.3971791504340647\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.3955230635968232\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.3955474096028666\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.3961065572435025\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.3965766200878122\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.3945604172594352\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.3961411526320835\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.3965834114769788\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.3953353639551445\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.3954567278087437\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.3947247523881041\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.3961506996694877\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.3960074900360793\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.3956448309553906\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.3953899261959894\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.3950021493797105\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.3957044403581618\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.3960907010463248\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.3954066474322933\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3946950602220696\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.3950361481121352\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3964868194194877\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.3948031392943379\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.3957101922584534\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.3946846582373884\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.3958032731984862\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.3943570295763692\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.3966699170990764\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.3951094540719888\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.3946051895683924\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.3948424109319033\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.3950175747927354\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.395358443589415\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.3948161413094955\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.3953090212055548\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.3951132111471916\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.3951416177398404\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.394119809092807\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3953348842339919\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.3949353492075214\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.3946173195643068\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.395727851326414\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.39423336076915\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.3952350840753431\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.3947621447849743\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.3952690093176305\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.3944356848439383\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.3940795106447603\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.395405306057219\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.3953181358719395\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.3939333055066614\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.3950812210229584\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.3936133015194772\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.394946867672354\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.3949594041782116\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.3949083984089412\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.3938976471123068\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.3949880292366612\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.39495695279887\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.39420842342909\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.394150279586578\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.3948037251395282\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.3937011624011602\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.3944892352386056\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.3947054703739996\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.3944928546217903\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.3942652777153084\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.3946010051975797\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.3941778985330575\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3937757334772551\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.3947742168555342\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.3946061877106848\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.3937139269318308\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.3944419169663265\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.3938775953745206\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.394385096268544\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.394503162055821\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.3938910617444127\n",
      "Epoch: 632, Iteration: 1/2, Loss: 1.3940712588232205\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3937341191079304\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.3947606242717274\n",
      "Epoch: 635, Iteration: 1/2, Loss: 1.3933619771005668\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.3938859400685273\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.3935903707455228\n",
      "Epoch: 638, Iteration: 1/2, Loss: 1.3949802310920039\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.3935507614971876\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.3939593078782235\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.3941259656875058\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.3943329970520157\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.393340324264669\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.393763909251687\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.3937095994580626\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.3941167741707239\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.3940380999810469\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.3935498535709294\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.394130408324907\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.3935505622557423\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.3940119594046667\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.3934125466271432\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.3934209266958661\n",
      "Epoch: 654, Iteration: 1/2, Loss: 1.3939538580070057\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.3934339778043525\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.3936301255293202\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.3939386261855973\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.39349667681574\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3936844073232528\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.3935294236409552\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.3931853197497888\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.3944572231734225\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.39311930671924\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.393844854532696\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.3933339410796481\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.3935385841179675\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.3929118948732169\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.3937890802769424\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3935838053248157\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.3934314717533152\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.3932789697286712\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.3941608610107274\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.3933807799226978\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.3933645498744651\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3924476446103573\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.393959827626491\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.392519289790644\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.393860481162012\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.393348917130064\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.3926511648658115\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.3932557478280656\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.3942351446615504\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.3928431171551492\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.3932736236722834\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.393125268616863\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.3933158777476078\n",
      "Epoch: 687, Iteration: 1/2, Loss: 1.3934611895578493\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.3922715600711784\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.393270549877017\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.393182553889104\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.393265958155387\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.3932164807082283\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.3930045376116325\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.39325685837463\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.3926766996648958\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.3930654698381695\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.3929707468061108\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.3930601402004774\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.3935110531228823\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.392676732446974\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.392654665767089\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.393300281305176\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.3925045000105039\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.3928446551693254\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.39308341547631\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.3928820377777429\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.3931631430958817\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.392599151094117\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.3928366921628812\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3930507243368169\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.3927125065128556\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.3924499400332941\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.393422431821975\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.3921973544097195\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.3925941541618858\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.3930020920483464\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.3925678952400273\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.3934052600511637\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.391725809900408\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.3932543713321717\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.392557300277959\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.3928427899123443\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.3927143644553661\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3925700623957684\n",
      "Epoch: 725, Iteration: 1/2, Loss: 1.39194260823114\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.3926101327322802\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3936121608636414\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.3923674668099189\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.3919870253748008\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.3927450701527857\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.3926018858241895\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.3926227012672068\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.3924832211030225\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.3926617959705658\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.3923366532464758\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.392480251223528\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.392291699382032\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.3926102740173218\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.3925548615345744\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3925551021739002\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3920891686168568\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.392251176596116\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.3926940380306898\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.392497023189892\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.3926938644560771\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.3913792313627202\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3928217922695647\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.3925038046523341\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.3921674899716368\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.39234335255045\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.392259694100605\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.392228466256511\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.3923621064741094\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.392054114596947\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.3921327995717774\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.3927606557430514\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.3917567582171102\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.3924238630687797\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.3919379151090365\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.392937730529321\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3917470771798195\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.392133373007935\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.3925644368236099\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.3913066264718918\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.3923934779168248\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.3920618234350544\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.3921109172089519\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.3924101649641978\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.3920345501835854\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.3915672418416973\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.3927431542244808\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.3916860016285546\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.3921541302366647\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3918092379848341\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.3923290939940793\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.3915580286559535\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.3923131336938233\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.3920714688861329\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.3919448555760308\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.3917712322424776\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.392401058801869\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3913318873644378\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.3925977400302194\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.391403548513809\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.3919390616631333\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.3921449008084639\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.3918913732354898\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.3917800791250812\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.391919719681611\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.3916444261095218\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.3921470117096917\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.3917576974657169\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.3914252672900238\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.3924671682668976\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.3915955204663748\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.3916030971705227\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.3922209078494547\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.3919400784851923\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.391578589580876\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.3915465635973507\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.3915048862064718\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.3917874775168388\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.391679216115206\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.3917673185676973\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.391708392100128\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.3918893769162426\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3914482602113463\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.391935217973567\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.3919063145612687\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.3913242380691768\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.3915125463504348\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.391869905915905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2144.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 813, Iteration: 1/2, Loss: 1.3913746261718658\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.391644024568121\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.3920755576635993\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.391395279051098\n",
      "Epoch: 817, Iteration: 1/2, Loss: 1.3913553136656867\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3919974202422967\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.3915943224579432\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.3908975978351887\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.391733343953875\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3917770524149966\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.391301782790856\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.3918507711463042\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.3913453772727364\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.3915817732132747\n",
      "Epoch: 827, Iteration: 1/2, Loss: 1.3913129284014563\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3917187129000093\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.3912246758714213\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.3912697731051542\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.3919121316067944\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.391422337151381\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.3914420361814113\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.3912856991169225\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.3919282057268123\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.3912388297943934\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.3910051141426667\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.3912453854276365\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.3919402760454571\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.3909806203140174\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.3916632861682685\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.391489525333307\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.3909325295376804\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.3919585535853674\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.3910669001721125\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.39127182475218\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.391272728973873\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.3912814413832062\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.3913734294313178\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.390810492257852\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.391890973909033\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3912964084459511\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.3910027361171264\n",
      "Epoch: 854, Iteration: 1/2, Loss: 1.3913299708261193\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.3908166476828216\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.391241898149582\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.391446382739416\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.391203077531688\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.3912385771812354\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.3913546859107702\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.3912702534921642\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3911635778601146\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.3909509492262968\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.3913911431721955\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.3913063093640032\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.3911581400580115\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.3910536636814672\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.3911417298102258\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.3911071752715571\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.3911527991639898\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.39116069501681\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.3908113459666334\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3909807854173344\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.3914280136757426\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.3910169570991284\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.391494916384592\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.3903476219196391\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.3912467522101628\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3910546298500144\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.3910258500346264\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.391039598945563\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.3910317929391667\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.3916184257313042\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.3908327462733532\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.3907366300888846\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.3914513862571818\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.3909917706522672\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.390984072753541\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.3907956777110968\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.3907417614300142\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.39132765018838\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.390655798219592\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.3908389920965667\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.3908211309634868\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.3909524106870697\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.390726073655395\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3910755857344992\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.391047499690633\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.391302900124773\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.3906403773192908\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.3907808954900913\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.390879812263298\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3910943403854445\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.390884727068367\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.3906173415882521\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.3912068782337348\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.390487136350778\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3905062026112103\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.390984844599955\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.3909574630221813\n",
      "Epoch: 911, Iteration: 1/2, Loss: 1.3908146740239515\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.391239715471115\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.3906262854274205\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.3904411224120228\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.3906339168646005\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.3909132470963637\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3906394391741679\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.390765875150235\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.3912406489470854\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.3902706536011813\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.39089668006945\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.3907822328275765\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.3905357143920782\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.3908365677712398\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.3907561975414082\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.3909439093828762\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.3907028245868172\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.3905948273625883\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.3907520786968801\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.390339820907725\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3911874035338825\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.3906503771284782\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.390320802881776\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.390618727568331\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.3906878373731848\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.3906055242207864\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.3905264479546768\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.39082020697027\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.3910852459705079\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.3902636005632214\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.390647034097892\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.390768859819416\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.3904314614435553\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.3906751487867999\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.390125195623273\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.391114258992792\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.3904064918958237\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.3906487830901182\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.390449341034485\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.3907195900980935\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.3900303679210255\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.3910340335824243\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.390075477494542\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.3906701894642395\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.3903392137439756\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.3911491561900138\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.3900159363551197\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.3908065458144145\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.3904469882994932\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.3903552236501437\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.3907202866307027\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.39000678573573\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.3906119639768977\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.3909501360954812\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.3899713567555918\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.3907762169971414\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.3903027254078624\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3905218131333026\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.390614078772901\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.3901402660794933\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3904433863486831\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.3902157003772933\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.3907653231801496\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.3900641066986568\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.3905772195127675\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.3901756371050131\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.3903853905382197\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.3904145414427287\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3908487787206174\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.3900129093859015\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.3902804587621835\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3906497807451461\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.3902288533957294\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.3906018308345327\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.3901643184477628\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.390211989368706\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.3904058541157849\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.3900460269193107\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.390296941139273\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.3906002828591721\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.3900299136522023\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.3906438417612996\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.3899458875562116\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.3907324595440311\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.3901788164860864\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.3900661755231942\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.3902687788531423\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.3903976352806802\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3900434335266127\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3904211941253541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(len(word2idx), hidden_size, window_size)\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language : [-2.35553051  1.66218403  0.81758376  0.23098241  0.99074151]\n",
      "processing : [ 0.77351129  0.37766188  0.37698466 -2.66391566  0.46588108]\n",
      ". : [ 0.00731923 -0.01722419 -0.00193782  0.01087549 -0.00870397]\n",
      "natural : [ 1.30576896 -1.68907812 -1.79722907 -1.51560245 -0.0351501 ]\n",
      "i : [ 0.00843583 -0.0069537  -0.00501326  0.00985574  0.0028239 ]\n",
      "am : [ 1.94908085 -1.07066873 -1.101271    1.5390706  -0.06243295]\n",
      "now : [-0.09163671  0.45690414  2.12446589  1.79903814  0.77317635]\n",
      "studying : [-2.12251007  0.41067518 -0.62633774 -0.44384983 -1.66396388]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "word_vec = skip_gram.word_vecs\n",
    "for i in word2idx.keys():\n",
    "    print(i,':',word_vec[word2idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
